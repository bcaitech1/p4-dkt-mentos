{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2bbe9fb-a044-42b5-a2dc-1113f78c21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from args_jupyter import parse_args\n",
    "from dkt.dataloader import Preprocess\n",
    "from dkt import trainer\n",
    "import torch\n",
    "from dkt.utils import setSeeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79f721a-ca32-468c-a93b-24c8f9285071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "from dkt.dataloader import get_loaders\n",
    "from dkt.optimizer import get_optimizer, get_lr\n",
    "from dkt.scheduler import get_scheduler\n",
    "from dkt.criterion import get_criterion\n",
    "from dkt.metric import get_metric\n",
    "from dkt.model import LSTM, LSTMATTN, Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ceefac-0a8b-461c-9fae-0925033a422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args(mode='train')\n",
    "setSeeds(args.seed)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0cf579-64e8-4947-98a5-40cdf6894107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 전처리\n",
    "def process_batch(batch, args):\n",
    "\n",
    "    test, question, tag, correct, mask = batch\n",
    "    \n",
    "    \n",
    "    # change to float\n",
    "    mask = mask.type(torch.FloatTensor)\n",
    "    correct = correct.type(torch.FloatTensor)\n",
    "\n",
    "    #  interaction을 임시적으로 correct를 한칸 우측으로 이동한 것으로 사용\n",
    "    #    saint의 경우 decoder에 들어가는 input이다\n",
    "    interaction = correct + 1 # 패딩을 위해 correct값에 1을 더해준다.\n",
    "    interaction = interaction.roll(shifts=1, dims=1)\n",
    "    interaction[:, 0] = 0 # set padding index to the first sequence\n",
    "    interaction = (interaction * mask).to(torch.int64)\n",
    "    # print(interaction)\n",
    "    # exit()\n",
    "    #  test_id, question_id, tag\n",
    "    test = ((test + 1) * mask).to(torch.int64)\n",
    "    question = ((question + 1) * mask).to(torch.int64)\n",
    "    tag = ((tag + 1) * mask).to(torch.int64)\n",
    "\n",
    "    # gather index\n",
    "    # 마지막 sequence만 사용하기 위한 index\n",
    "    gather_index = torch.tensor(np.count_nonzero(mask, axis=1))\n",
    "    gather_index = gather_index.view(-1, 1) - 1\n",
    "\n",
    "\n",
    "    # device memory로 이동\n",
    "\n",
    "    test = test.to(args.device)\n",
    "    question = question.to(args.device)\n",
    "\n",
    "\n",
    "    tag = tag.to(args.device)\n",
    "    correct = correct.to(args.device)\n",
    "    mask = mask.to(args.device)\n",
    "\n",
    "    interaction = interaction.to(args.device)\n",
    "    gather_index = gather_index.to(args.device)\n",
    "\n",
    "    return (test, question,\n",
    "            tag, correct, mask,\n",
    "            interaction, gather_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a04ef2d-a666-4c95-a95d-f9043a368af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocess(args)\n",
    "preprocess.load_train_data(args.file_name)\n",
    "train_data = preprocess.get_train_data()\n",
    "\n",
    "train_data, valid_data = preprocess.split_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25bf1672-12da-4592-8a6d-d8bc24c02856",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = get_loaders(args, train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2140465-5ef1-4657-a0c2-5bfe039ef9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testID size: torch.Size([64, 20])\n",
      "assessmentItemId size: torch.Size([64, 20])\n",
      "knowledgetag size: torch.Size([64, 20])\n",
      "answercode size: torch.Size([64, 20])\n",
      "mask size: torch.Size([64, 20])\n"
     ]
    }
   ],
   "source": [
    "batch = None\n",
    "for t in train_loader:\n",
    "    # train_loader is tuple\n",
    "    \n",
    "    print(f\"testID size: {t[0].size()}\")\n",
    "    print(f\"assessmentItemId size: {t[1].size()}\")\n",
    "    print(f\"knowledgetag size: {t[2].size()}\")\n",
    "    print(f\"answercode size: {t[3].size()}\")\n",
    "    print(f\"mask size: {t[4].size()}\")\n",
    "    \n",
    "    batch = t\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a87d848-cb61-4a16-890d-35a3ce19dcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(asset_dir='asset/', batch_size=64, clip_grad=10, data_dir='/opt/ml/input/data/train_dataset', device='cpu', drop_out=0.2, emb_size=100, file_name='train_data.csv', hidden_dim=64, log_steps=50, lr=0.0001, max_seq_len=20, model='lstm', model_dir='models/', model_name='model.pt', n_epochs=20, n_heads=2, n_layers=2, n_questions=9455, n_tag=913, n_test=1538, num_workers=1, optimizer='adam', output_dir='output/', patience=5, scheduler='plateau', seed=5, test_file_name='test_data.csv', wandb_name=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda08c9c-e1e9-4aee-aff0-4ccd0c56dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba3e1585-22f2-4b9a-87ec-ad26905fa93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = process_batch(batch, args)\n",
    "# test, question, tag, correct, mask, interaction, gather_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c3bcbc-837b-4a83-ac92-18c95e79cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test, question, tag, _, mask, interaction, _ = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d214bd30-2ab1-432b-be18-5dcc6756f82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c9b0a30-a7de-4861-8d1d-7e4587593b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "313a1671-4823-45f0-8610-0e5ea99cccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1, temp2 = mask.view(args.batch_size, args.max_seq_len, -1).max(2)\n",
    "temp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "806a4e8e-3ff1-4ad4-93c9-0781a60579c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_attention_mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
    "extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "head_mask = [None] * args.n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38da7bf-6d7d-466d-9814-e2411c63660c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 1, 20]), 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask.shape, len(head_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "380ef79c-f902-4fcb-a5c6-f66c77efe665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0., -0., -0.,  ..., -0., -0., -0.]]],\n",
       "\n",
       "\n",
       "        [[[-0., -0., -0.,  ..., -0., -0., -0.]]],\n",
       "\n",
       "\n",
       "        [[[-0., -0., -0.,  ..., -0., -0., -0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0., -0., -0.,  ..., -0., -0., -0.]]],\n",
       "\n",
       "\n",
       "        [[[-0., -0., -0.,  ..., -0., -0., -0.]]],\n",
       "\n",
       "\n",
       "        [[[-0., -0., -0.,  ..., -0., -0., -0.]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac2bbf5-50d6-4fd9-af93-22e640fd2c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 20, 16])\n",
      "torch.Size([64, 20, 16])\n",
      "torch.Size([64, 20, 16])\n",
      "torch.Size([64, 20, 16])\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = args.hidden_dim\n",
    "n_layers = args.n_layers\n",
    "device\n",
    "\n",
    "# Embedding \n",
    "# interaction은 현재 correct로 구성되어있다. correct(1, 2) + padding(0)\n",
    "embedding_interaction = nn.Embedding(3, hidden_dim//4)\n",
    "embedding_test = nn.Embedding(args.n_test + 1, hidden_dim//4)\n",
    "embedding_question = nn.Embedding(args.n_questions + 1, hidden_dim//4)\n",
    "embedding_tag = nn.Embedding(args.n_tag + 1, hidden_dim//4)\n",
    "\n",
    "embed_interaction = embedding_interaction(interaction)\n",
    "embed_test = embedding_test(test)\n",
    "embed_question = embedding_question(question)\n",
    "embed_tag = embedding_tag(tag)\n",
    "\n",
    "print(embed_interaction.size())\n",
    "print(embed_test.size())\n",
    "print(embed_question.size())\n",
    "print(embed_tag.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1a09f74-995b-48b9-b2ef-fdb25855ccd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = torch.cat([embed_interaction,\n",
    "                   embed_test,\n",
    "                   embed_question,\n",
    "                   embed_tag,], 2)\n",
    "embed.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5cc4f15-ae0a-4430-9a91-2b582359cf15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 64])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding combination projection\n",
    "comb_proj = nn.Sequential(nn.Linear(hidden_dim, hidden_dim), nn.LayerNorm(hidden_dim))\n",
    "\n",
    "comb_embed = comb_proj(embed)\n",
    "comb_embed.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85778255-5710-4626-8c48-d254ca31a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from transformers.modeling_bert import BertConfig, BertEncoder, BertModel    \n",
    "except:\n",
    "    from transformers.models.bert.modeling_bert import BertConfig, BertEncoder, BertModel   \n",
    "\n",
    "config = BertConfig(3, # not used\n",
    "                    hidden_size=hidden_dim,\n",
    "                    num_hidden_layers=args.n_layers,\n",
    "                    num_attention_heads=args.n_heads,\n",
    "                    intermediate_size=args.hidden_dim,\n",
    "                    hidden_dropout_prob=args.drop_out,\n",
    "                    attention_probs_dropout_prob=args.drop_out)\n",
    "\n",
    "encoder = BertEncoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56817efc-7351-4a9f-932f-560e13f71c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 64])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers = encoder(comb_embed)\n",
    "sequence_output = encoded_layers[-1]\n",
    "sequence_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2202e93-fd0a-4a35-8054-cefb4bd2fc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_output = sequence_output[:, -1]\n",
    "sequence_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1daf20e5-78d9-4eb6-b99b-71ce6902a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg():\n",
    "    return nn.Sequential(nn.Linear(args.hidden_dim, args.hidden_dim),\n",
    "                         nn.LayerNorm(args.hidden_dim),\n",
    "                         nn.Dropout(args.drop_out),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Linear(args.hidden_dim, 1))\n",
    "\n",
    "reg_layer = get_reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fe8fc29-86be-44ae-a0dc-a91291354da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.Size([64, 20, 64]) -> [64, 1]\n",
    "pred_y = reg_layer(sequence_output)\n",
    "pred_y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2d5a0-3aa8-4039-8472-627533d782ef",
   "metadata": {},
   "source": [
    "### 클래스로 만들기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32be3029-5e40-4e06-a590-5d944f3334d1",
   "metadata": {},
   "source": [
    "n_rows_per_step = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5414c2d1-d341-49e0-9ed7-aef8cdad3bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# riiid rank 7\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.args = args\n",
    "        # Embedding \n",
    "        # interaction은 현재 correct로 구성되어있다. correct(1, 2) + padding(0)\n",
    "        self.embedding_interaction = nn.Embedding(3, args.hidden_dim//4)\n",
    "        self.embedding_test = nn.Embedding(args.n_test + 1, args.hidden_dim//4)\n",
    "        self.embedding_question = nn.Embedding(args.n_questions + 1, args.hidden_dim//4)\n",
    "        self.embedding_tag = nn.Embedding(args.n_tag + 1, args.hidden_dim//4)\n",
    "\n",
    "        # embedding combination projection\n",
    "        self.comb_proj = nn.Sequential(nn.Linear(args.hidden_dim, args.hidden_dim), \n",
    "                                  nn.LayerNorm(args.hidden_dim))\n",
    "        \n",
    "        config = BertConfig(3, # not used\n",
    "                    hidden_size=args.hidden_dim,\n",
    "                    num_hidden_layers=args.n_layers,\n",
    "                    num_attention_heads=args.n_heads,\n",
    "                    intermediate_size=args.hidden_dim,\n",
    "                    hidden_dropout_prob=args.drop_out,\n",
    "                    attention_probs_dropout_prob=args.drop_out)\n",
    "        \n",
    "        self.encoder = BertEncoder(config)\n",
    "\n",
    "        def get_reg():\n",
    "            return nn.Sequential(nn.Linear(args.hidden_dim, args.hidden_dim),\n",
    "                                 nn.LayerNorm(args.hidden_dim),\n",
    "                                 nn.Dropout(args.drop_out),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(args.hidden_dim, 1),\n",
    "                                 nn.Sigmoid())\n",
    "\n",
    "        self.reg_layer = get_reg()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        test, question, tag, _, mask, interaction, _ = inputs\n",
    "        batch_size = interaction.size(0)\n",
    "        \n",
    "        embed_interaction = self.embedding_interaction(interaction)\n",
    "        embed_test = self.embedding_test(test)\n",
    "        embed_question = self.embedding_question(question)\n",
    "        embed_tag = self.embedding_tag(tag)\n",
    "\n",
    "        embed = torch.cat([embed_interaction,\n",
    "                       embed_test,\n",
    "                       embed_question,\n",
    "                       embed_tag,], 2)\n",
    "        \n",
    "        comb_embed = self.comb_proj(embed)\n",
    "        \n",
    "        extended_attention_mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "        extended_attention_mask = extended_attention_mask.to(dtype=torch.float32)\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        \n",
    "#         mask, _ = mask.view(batch_size, args.max_seq_len, -1).max(2)\n",
    "        \n",
    "        encoded_layers = self.encoder(comb_embed, attention_mask= extended_attention_mask)\n",
    "        sequence_output = encoded_layers[0]  # 길이 1이라서 0과 -1 같음\n",
    "        # sequence_output은 [64, 20, 64]\n",
    "        # sequence_output = sequence_output[:, -1]\n",
    "        \n",
    "        pred_y = self.reg_layer(sequence_output).view(batch_size, -1)  # [64, 20, 64] -> [64, 20, 1]\n",
    "        \n",
    "        return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36453413-1e9f-4acb-93b0-bbdab56cf726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size : torch.Size([64, 20])\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(args)\n",
    "\n",
    "for step, batch in enumerate(train_loader):\n",
    "    inputs = process_batch(batch, args)\n",
    "    output = model(inputs)\n",
    "    print(f\"output size : {output.size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "612c0e54-8f46-4422-8395-56624cad5f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5435, 0.5199, 0.5476,  ..., 0.4855, 0.5477, 0.4420],\n",
       "        [0.5780, 0.4721, 0.3875,  ..., 0.4301, 0.6226, 0.6035],\n",
       "        [0.5190, 0.5130, 0.4998,  ..., 0.3284, 0.4155, 0.2817],\n",
       "        ...,\n",
       "        [0.5990, 0.5744, 0.4462,  ..., 0.5712, 0.4767, 0.4135],\n",
       "        [0.5131, 0.5915, 0.6935,  ..., 0.5372, 0.5526, 0.4999],\n",
       "        [0.3874, 0.5622, 0.6337,  ..., 0.6429, 0.5470, 0.4966]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de802df5-ad4c-4765-b7b3-624d8866e374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
