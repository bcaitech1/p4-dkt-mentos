{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09aeab31-d79b-48f3-b851-e9260a86f48d",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4494faab-aedc-47ed-bd25-aacf05670248",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/train_dataset'\n",
    "file_name = 'train_data.csv'\n",
    "test_file_name = 'test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796f7000-8c66-4d61-8c08-4c525f08477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_id = 'cycle' # 'user' or 'cycle'\n",
    "y_method = 'last' # 'last' or 'next'\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c1919-ff16-4f9e-ba4a-5e195ddf6c6e",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adad225b-64bc-42a8-b2c6-8588b83757b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import easydict\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from fe.feature import FEPipeline\n",
    "from fe.agg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cd40f2-26f6-40fd-b285-4a62ec93cdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_id2columns(y_id):\n",
    "    if y_id == 'user':\n",
    "        y_id = 'userID'\n",
    "    elif y_id == 'cycle':\n",
    "        y_id = ['userID', 'testId', 'Retest']\n",
    "    \n",
    "    return y_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ad4226-2958-4517-bcb8-570af076d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(s):\n",
    "    timestamp = time.mktime(datetime.strptime(s, '%Y-%m-%d %H:%M:%S').timetuple())\n",
    "    return int(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5837efc2-2a63-4ab4-bf15-aca0316b213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    preprocess_df_path = '/opt/ml/features/preprocess.csv'\n",
    "    \n",
    "    if not os.path.exists(preprocess_df_path):\n",
    "        # YYYY-MM-DD HH:MM:SS -> sec format\n",
    "        df['Timestamp'] = df['Timestamp'].apply(convert_time)\n",
    "        \n",
    "        # 한 문제 푸는데 걸린 시간\n",
    "        df['time_diff'] = df['Timestamp'] - df['Timestamp'].shift(1)\n",
    "        \n",
    "        # userID 별 푼 문항의 누적 합\n",
    "        df['UserCumtestnum'] = df.groupby(['userID'])['answerCode'].cumcount()\n",
    "\n",
    "        # userID, KnowledgeTag 별 푼 문항의 누적 합\n",
    "        df['UserTagCumtestnum'] = df.groupby(['userID', 'KnowledgeTag'])['answerCode'].cumcount()\n",
    "\n",
    "        # userID, testId 별 푼 문항의 누적 합\n",
    "        df['UserTestCumtestnum'] = df.groupby(['userID','testId'])['answerCode'].cumcount()\n",
    "\n",
    "        testId2maxlen = df[['assessmentItemID', 'testId']].drop_duplicates().groupby('testId').size()\n",
    "        # test의 문항 수\n",
    "        df['TestSize'] = df.testId.map(testId2maxlen)\n",
    "        # user가 같은 test를 여러 번 푼 것인지 나타낸 변수 (처음 품 : 0, 두번 품 : 1, 세번 품 : 2)\n",
    "        df['Retest'] = df['UserTestCumtestnum'] // df['TestSize']\n",
    "\n",
    "        # Cycle 별 푼 문항의 누적 합\n",
    "        df['UserCycleCumtestnum'] = df['UserTestCumtestnum'] % df['TestSize']        \n",
    "\n",
    "        df.to_csv(preprocess_df_path, index=False)\n",
    "        \n",
    "        print('* Success to save preprocessed df')\n",
    "\n",
    "    else:\n",
    "        df = pd.read_csv(preprocess_df_path)\n",
    "    \n",
    "        print('* Success to load preprocessed df')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff6d3ea-3d03-4095-a52a-d210671d16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_y(df, y_id, y_method):\n",
    "    if y_method == 'last':\n",
    "        # y_id 별 마지막 행을 y로\n",
    "        y = df.groupby(y_id)['answerCode'].apply(lambda x: list(x)[-1])\n",
    "        y.name = 'y'\n",
    "        df = df.merge(y, how=\"inner\", on=y_id)\n",
    "\n",
    "        # y_id 별 마지막 행 제거\n",
    "        last_idx = df.groupby(y_id).apply(lambda x: x.index[-1]).values\n",
    "        df = df.drop(last_idx)\n",
    "    \n",
    "    elif y_method == 'next':\n",
    "        # 다음 answerCode를 y로\n",
    "        df['y'] = df.answerCode.shift(-1)\n",
    "\n",
    "        # y_id 별 마지막 행 제거\n",
    "        last_idx = df.groupby(y_id).apply(lambda x: x.index[-1]).values\n",
    "        df = df.drop(last_idx)\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"* Success to set y by method '{y_method}'\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "228e23b8-b39e-4374-8224-3776152f7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cumdata(df):\n",
    "    preprocess_df_path = '/opt/ml/features/cumdata.csv'\n",
    "    \n",
    "    if not os.path.exists(preprocess_df_path):\n",
    "        temp_df = pd.DataFrame(df.userID)\n",
    "        \n",
    "        # test의 문항 번호\n",
    "        temp_df['testNumber'] = [int(assessment[-3:]) for assessment in df.assessmentItemID]\n",
    "\n",
    "        # userID 별 맞춘 문항의 누적 합\n",
    "        temp_df[\"UserCumcorrectnum\"] = df.groupby(['userID'])['answerCode'].apply(lambda x: x.cumsum().shift(1))\n",
    "        # userID 별 누적 정답률\n",
    "        temp_df[\"UserCumcorrectper\"] = temp_df['UserCumcorrectnum'] / df['UserCumtestnum']\n",
    "\n",
    "        # userID, KnowledgeTag 별 맞춘 문항의 누적 합\n",
    "        temp_df[\"UserTagCumcorrectnum\"] = df.groupby(['userID', 'KnowledgeTag'])['answerCode'].apply(lambda x: x.cumsum().shift(1))\n",
    "        temp_df[\"UserTagCumcorrectnum\"] = temp_df[\"UserTagCumcorrectnum\"].fillna(0)\n",
    "        # userID, KnowledgeTag 별 누적 정답률\n",
    "        temp_df[\"UserTagCumcorrectper\"] = temp_df['UserTagCumcorrectnum'] / df['UserTagCumtestnum']\n",
    "        temp_df[\"UserTagCumcorrectper\"] = temp_df[\"UserTagCumcorrectper\"].fillna(0)\n",
    "\n",
    "        # userID, testId 별 맞춘 문항의 누적 합\n",
    "        temp_df[\"UserTestCumcorrectnum\"] = df.groupby(['userID','testId'])['answerCode'].apply(lambda x: x.cumsum().shift(1))\n",
    "        # userID, testId 별 누적 정답률\n",
    "        temp_df[\"UserTestCumcorrectper\"] = temp_df['UserTestCumcorrectnum'] / df['UserTestCumtestnum']\n",
    "\n",
    "        # Cycle 별 맞춘 문항의 누적 합\n",
    "        temp_df['UserCycleCumcorrectnum'] = df.groupby(['userID','testId','Retest'])['answerCode'].apply(lambda x: x.cumsum().shift(1))\n",
    "        # Cycle 별 누적 정답률\n",
    "        temp_df['UserCycleCumcorrectper'] = temp_df['UserCycleCumcorrectnum']/df['UserCycleCumtestnum']\n",
    "        \n",
    "        temp_df = temp_df.drop('userID', axis=1)\n",
    "        temp_df.to_csv(preprocess_df_path, index=False)\n",
    "        \n",
    "        print('* Success to save cumulative data')\n",
    "    \n",
    "    else:\n",
    "        temp_df = pd.read_csv(preprocess_df_path)\n",
    "    \n",
    "        print('* Success to load cumulative data')\n",
    "\n",
    "    df = pd.concat([df, temp_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4308e042-c2b7-49b7-a22b-074630c34034",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = os.path.join(data_dir, file_name)\n",
    "train_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "test_csv_file_path = os.path.join(data_dir, test_file_name)\n",
    "test_df = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1025fa0-e1c1-4cf7-bdc4-c3a16b6dbb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Success to load preprocessed df\n",
      "* Success to set y by method 'last'\n",
      "* Success to load cumulative data\n"
     ]
    }
   ],
   "source": [
    "y_id = y_id2columns(y_id)\n",
    "df = df.sort_values(by=['userID','Timestamp']).reset_index(drop=True)\n",
    "df = preprocess(df)\n",
    "df = set_y(df, y_id, y_method)\n",
    "df = make_cumdata(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a68c628-5bea-495b-b03f-b9b5d495c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({'root_dir' : './'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "831742e7-bb63-42af-b58c-1de47824ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 건모님의 FE class\n",
    "FEpl = FEPipeline(args, [MakeQuestionCount, \n",
    "                         MakeCorrectCount, \n",
    "                         MakeCorrectPercent, \n",
    "                         MakeTopNCorrectPercent,\n",
    "                         MakeTagAnswerData,\n",
    "                         MakeUserTagAnswerData,\n",
    "                         MakeTestAnswerData,\n",
    "                         MakeUserTestAnswerData,\n",
    "                         MakeAssessmentAnswerData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc018606-8ff2-42ee-9669-22fefef91d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEpl.debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70a148b8-903d-455c-873a-bb8de5e5791f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Descriptions]\n",
      "\n",
      "feature name : base_feature\n",
      "feature type : seq\n",
      " - userID               : 사용자의 고유 번호입니다. 총 7,442명의 학생이 있습니다\n",
      " - assessmentItemID     : 사용자가 푼 문항의 일련 번호입니다.\n",
      " - testID               : 사용자가 푼 문항이 포함된 시험지의 일련 번호입니다.\n",
      " - answerCode           : 사용자가 푼 문항의 정답 여부를 담고 있는 이진 (0/1) 데이터입니다.\n",
      " - Timestamp            : 사용자가 문항을 푼 시간 정보입니다.\n",
      " - KnowledgeTag         : 사용자가 푼 문항의 고유 태그가 담겨져 있습니다.\n",
      "\n",
      "feature name : make_question_count\n",
      "feature type : agg\n",
      " - quesCnt              : 사용자가 푼 문항수를 나타냅니다.\n",
      "\n",
      "feature name : make_correct_count\n",
      "feature type : agg\n",
      " - correctCnt           : 사용자가 맞춘 문항수를 나타냅니다.\n",
      "\n",
      "feature name : make_correct_percent\n",
      "feature type : agg\n",
      " - correctPer           : 사용자가 푼 전체 문항에 대한 정답률입니다.\n",
      "\n",
      "feature name : make_topn_correct_percent\n",
      "feature type : agg\n",
      " - top10CorrectPer      : 사용자가 최근 푼 TOP-10개에 대한 정답률입니다.\n",
      " - top30CorrectPer      : 사용자가 최근 푼 TOP-30개에 대한 정답률입니다.\n",
      " - top50CorrectPer      : 사용자가 최근 푼 TOP-50개에 대한 정답률입니다.\n",
      " - top100CorrectPer     : 사용자가 최근 푼 TOP-100개에 대한 정답률입니다.\n",
      "\n",
      "feature name : make_tag_answer_data\n",
      "feature type : agg\n",
      " - TagCorrectPer        : KnowledgeTag 별 정답률입니다.\n",
      " - TagCorrectSum        : KnowledgeTag 별 정답 문항 수의 합입니다.\n",
      "\n",
      "feature name : make_user_tag_answer_data\n",
      "feature type : agg\n",
      " - UserTagCorrectPer    : userID, KnowledgeTag 별 정답률입니다.\n",
      " - UserTagCorrectSum    : userID, KnowledgeTag 별 정답 문항 수의 합입니다.\n",
      "\n",
      "feature name : make_test_answer_data\n",
      "feature type : agg\n",
      " - TestCorrectPer       : testId 별 정답률입니다.\n",
      " - TestCorrectSum       : testId 별 정답 문항 수의 합입니다.\n",
      "\n",
      "feature name : make_user_test_answer_data\n",
      "feature type : agg\n",
      " - UserTestCorrectPer   : userID, testId 별 정답률입니다.\n",
      " - UserTestCorrectSum   : userID, testId 별 정답 문항 수의 합입니다.\n",
      "\n",
      "feature name : make_assessment_answer_data\n",
      "feature type : agg\n",
      " - AssessmentCorrectPer : assessmentItemID 별 정답률입니다.\n",
      " - AssessmentCorrectSum : assessmentItemID 별 정답 문항 수의 합입니다.\n"
     ]
    }
   ],
   "source": [
    "FEpl.description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e835c20-4b4c-4d98-afd8-48ac1f540c51",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Engineering Start ... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load features /opt/ml/features/train_make_question_count.pkl to dataframe ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Name: make_question_count\n",
      "\n",
      "quesCnt         : 사용자가 푼 문항수를 나타냅니다.\n",
      "dtype: int64\n",
      "[Examples]\n",
      "INDEX 0000: 641\n",
      "INDEX 1000: 641\n",
      "INDEX 2000: 641\n",
      "INDEX 3000: 641\n",
      "INDEX 4000: 641\n",
      "INDEX 5000: 641\n",
      "INDEX 6000: 641\n",
      "INDEX 7000: 770\n",
      "INDEX 8000: 770\n",
      "INDEX 9000: 770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load features /opt/ml/features/train_make_correct_count.pkl to dataframe ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Name: make_correct_count\n",
      "\n",
      "correctCnt      : 사용자가 맞춘 문항수를 나타냅니다.\n",
      "dtype: int64\n",
      "[Examples]\n",
      "INDEX 0000: 422\n",
      "INDEX 1000: 422\n",
      "INDEX 2000: 422\n",
      "INDEX 3000: 422\n",
      "INDEX 4000: 422\n",
      "INDEX 5000: 422\n",
      "INDEX 6000: 422\n",
      "INDEX 7000: 673\n",
      "INDEX 8000: 673\n",
      "INDEX 9000: 673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load features /opt/ml/features/train_make_correct_percent.pkl to dataframe ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Name: make_correct_percent\n",
      "\n",
      "correctPer      : 사용자가 푼 전체 문항에 대한 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 0.6583463338533542\n",
      "INDEX 1000: 0.6583463338533542\n",
      "INDEX 2000: 0.6583463338533542\n",
      "INDEX 3000: 0.6583463338533542\n",
      "INDEX 4000: 0.6583463338533542\n",
      "INDEX 5000: 0.6583463338533542\n",
      "INDEX 6000: 0.6583463338533542\n",
      "INDEX 7000: 0.874025974025974\n",
      "INDEX 8000: 0.874025974025974\n",
      "INDEX 9000: 0.874025974025974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load features /opt/ml/features/train_make_topn_correct_percent.pkl to dataframe ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Name: make_topn_correct_percent\n",
      "\n",
      "top10CorrectPer : 사용자가 최근 푼 TOP-10개에 대한 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 0.7\n",
      "INDEX 1000: 0.7\n",
      "INDEX 2000: 0.7\n",
      "INDEX 3000: 0.7\n",
      "INDEX 4000: 0.7\n",
      "INDEX 5000: 0.7\n",
      "INDEX 6000: 0.7\n",
      "INDEX 7000: 0.9\n",
      "INDEX 8000: 0.9\n",
      "INDEX 9000: 0.9\n",
      "\n",
      "top30CorrectPer : 사용자가 최근 푼 TOP-30개에 대한 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 0.6666666666666666\n",
      "INDEX 1000: 0.6666666666666666\n",
      "INDEX 2000: 0.6666666666666666\n",
      "INDEX 3000: 0.6666666666666666\n",
      "INDEX 4000: 0.6666666666666666\n",
      "INDEX 5000: 0.6666666666666666\n",
      "INDEX 6000: 0.6666666666666666\n",
      "INDEX 7000: 0.8666666666666667\n",
      "INDEX 8000: 0.8666666666666667\n",
      "INDEX 9000: 0.8666666666666667\n",
      "\n",
      "top50CorrectPer : 사용자가 최근 푼 TOP-50개에 대한 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 0.56\n",
      "INDEX 1000: 0.56\n",
      "INDEX 2000: 0.56\n",
      "INDEX 3000: 0.56\n",
      "INDEX 4000: 0.56\n",
      "INDEX 5000: 0.56\n",
      "INDEX 6000: 0.56\n",
      "INDEX 7000: 0.86\n",
      "INDEX 8000: 0.86\n",
      "INDEX 9000: 0.86\n",
      "\n",
      "top100CorrectPer : 사용자가 최근 푼 TOP-100개에 대한 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 0.71\n",
      "INDEX 1000: 0.71\n",
      "INDEX 2000: 0.71\n",
      "INDEX 3000: 0.71\n",
      "INDEX 4000: 0.71\n",
      "INDEX 5000: 0.71\n",
      "INDEX 6000: 0.71\n",
      "INDEX 7000: 0.88\n",
      "INDEX 8000: 0.88\n",
      "INDEX 9000: 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load features /opt/ml/features/train_make_tag_answer_data.pkl to dataframe ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Name: make_tag_answer_data\n",
      "\n",
      "TagCorrectPer   : KnowledgeTag 별 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 0.9586114819759679\n",
      "INDEX 1000: 0.9586114819759679\n",
      "INDEX 2000: 0.9586114819759679\n",
      "INDEX 3000: 0.9586114819759679\n",
      "INDEX 4000: 0.9586114819759679\n",
      "INDEX 5000: 0.9586114819759679\n",
      "INDEX 6000: 0.9586114819759679\n",
      "INDEX 7000: 0.9586114819759679\n",
      "INDEX 8000: 0.9166944351882705\n",
      "INDEX 9000: 0.9166944351882705\n",
      "\n",
      "TagCorrectSum   : KnowledgeTag 별 정답 문항 수의 합입니다.\n",
      "dtype: int64\n",
      "[Examples]\n",
      "INDEX 0000: 718\n",
      "INDEX 1000: 718\n",
      "INDEX 2000: 718\n",
      "INDEX 3000: 718\n",
      "INDEX 4000: 718\n",
      "INDEX 5000: 718\n",
      "INDEX 6000: 718\n",
      "INDEX 7000: 718\n",
      "INDEX 8000: 2751\n",
      "INDEX 9000: 2751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load features /opt/ml/features/train_make_user_tag_answer_data.pkl to dataframe ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Name: make_user_tag_answer_data\n",
      "\n",
      "UserTagCorrectPer : userID, KnowledgeTag 별 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 1.0\n",
      "INDEX 1000: 1.0\n",
      "INDEX 2000: 1.0\n",
      "INDEX 3000: 1.0\n",
      "INDEX 4000: 1.0\n",
      "INDEX 5000: 1.0\n",
      "INDEX 6000: 1.0\n",
      "INDEX 7000: 1.0\n",
      "INDEX 8000: 1.0\n",
      "INDEX 9000: 1.0\n",
      "\n",
      "UserTagCorrectSum : userID, KnowledgeTag 별 정답 문항 수의 합입니다.\n",
      "dtype: int64\n",
      "[Examples]\n",
      "INDEX 0000: 1\n",
      "INDEX 1000: 2\n",
      "INDEX 2000: 2\n",
      "INDEX 3000: 1\n",
      "INDEX 4000: 2\n",
      "INDEX 5000: 3\n",
      "INDEX 6000: 1\n",
      "INDEX 7000: 1\n",
      "INDEX 8000: 12\n",
      "INDEX 9000: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load features /opt/ml/features/train_make_test_answer_data.pkl to dataframe ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Name: make_test_answer_data\n",
      "\n",
      "TestCorrectPer  : testId 별 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 0.9576\n",
      "INDEX 1000: 0.9576\n",
      "INDEX 2000: 0.9576\n",
      "INDEX 3000: 0.9576\n",
      "INDEX 4000: 0.9576\n",
      "INDEX 5000: 0.9576\n",
      "INDEX 6000: 0.9576\n",
      "INDEX 7000: 0.9576\n",
      "INDEX 8000: 0.9576\n",
      "INDEX 9000: 0.9576\n",
      "\n",
      "TestCorrectSum  : testId 별 정답 문항 수의 합입니다.\n",
      "dtype: int64\n",
      "[Examples]\n",
      "INDEX 0000: 1197\n",
      "INDEX 1000: 1197\n",
      "INDEX 2000: 1197\n",
      "INDEX 3000: 1197\n",
      "INDEX 4000: 1197\n",
      "INDEX 5000: 1197\n",
      "INDEX 6000: 1197\n",
      "INDEX 7000: 1197\n",
      "INDEX 8000: 1197\n",
      "INDEX 9000: 1197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load features /opt/ml/features/train_make_user_test_answer_data.pkl to dataframe ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Name: make_user_test_answer_data\n",
      "\n",
      "UserTestCorrectPer : userID, testId 별 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 1.0\n",
      "INDEX 1000: 1.0\n",
      "INDEX 2000: 1.0\n",
      "INDEX 3000: 0.0\n",
      "INDEX 4000: 1.0\n",
      "INDEX 5000: 1.0\n",
      "INDEX 6000: 1.0\n",
      "INDEX 7000: 1.0\n",
      "INDEX 8000: 1.0\n",
      "INDEX 9000: 1.0\n",
      "\n",
      "UserTestCorrectSum : userID, testId 별 정답 문항 수의 합입니다.\n",
      "dtype: int64\n",
      "[Examples]\n",
      "INDEX 0000: 5\n",
      "INDEX 1000: 5\n",
      "INDEX 2000: 5\n",
      "INDEX 3000: 0\n",
      "INDEX 4000: 5\n",
      "INDEX 5000: 5\n",
      "INDEX 6000: 5\n",
      "INDEX 7000: 5\n",
      "INDEX 8000: 5\n",
      "INDEX 9000: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load features /opt/ml/features/train_make_assessment_answer_data.pkl to dataframe ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Name: make_assessment_answer_data\n",
      "\n",
      "AssessmentCorrectPer : assessmentItemID 별 정답률입니다.\n",
      "dtype: float64\n",
      "[Examples]\n",
      "INDEX 0000: 0.984\n",
      "INDEX 1000: 0.984\n",
      "INDEX 2000: 0.984\n",
      "INDEX 3000: 0.968\n",
      "INDEX 4000: 0.968\n",
      "INDEX 5000: 0.916\n",
      "INDEX 6000: 0.916\n",
      "INDEX 7000: 0.916\n",
      "INDEX 8000: 0.972\n",
      "INDEX 9000: 0.972\n",
      "\n",
      "AssessmentCorrectSum : assessmentItemID 별 정답 문항 수의 합입니다.\n",
      "dtype: int64\n",
      "[Examples]\n",
      "INDEX 0000: 246\n",
      "INDEX 1000: 246\n",
      "INDEX 2000: 246\n",
      "INDEX 3000: 242\n",
      "INDEX 4000: 242\n",
      "INDEX 5000: 229\n",
      "INDEX 6000: 229\n",
      "INDEX 7000: 229\n",
      "INDEX 8000: 243\n",
      "INDEX 9000: 243\n",
      "Feature Engineering End ... \n",
      "Original DataFrame Keywords: Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
      "       'KnowledgeTag', 'time_diff', 'UserCumtestnum', 'UserTagCumtestnum',\n",
      "       'UserTestCumtestnum', 'TestSize', 'Retest', 'UserCycleCumtestnum', 'y',\n",
      "       'testNumber', 'UserCumcorrectnum', 'UserCumcorrectper',\n",
      "       'UserTagCumcorrectnum', 'UserTagCumcorrectper', 'UserTestCumcorrectnum',\n",
      "       'UserTestCumcorrectper', 'UserCycleCumcorrectnum',\n",
      "       'UserCycleCumcorrectper'],\n",
      "      dtype='object')\n",
      "Feature Added DataFrame Keywords: Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
      "       'KnowledgeTag', 'time_diff', 'UserCumtestnum', 'UserTagCumtestnum',\n",
      "       'UserTestCumtestnum', 'TestSize', 'Retest', 'UserCycleCumtestnum', 'y',\n",
      "       'testNumber', 'UserCumcorrectnum', 'UserCumcorrectper',\n",
      "       'UserTagCumcorrectnum', 'UserTagCumcorrectper', 'UserTestCumcorrectnum',\n",
      "       'UserTestCumcorrectper', 'UserCycleCumcorrectnum',\n",
      "       'UserCycleCumcorrectper', 'quesCnt', 'correctCnt', 'correctPer',\n",
      "       'top10CorrectPer', 'top30CorrectPer', 'top50CorrectPer',\n",
      "       'top100CorrectPer', 'TagCorrectPer', 'TagCorrectSum',\n",
      "       'UserTagCorrectPer', 'UserTagCorrectSum', 'TestCorrectPer',\n",
      "       'TestCorrectSum', 'UserTestCorrectPer', 'UserTestCorrectSum',\n",
      "       'AssessmentCorrectPer', 'AssessmentCorrectSum'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "new_df = FEpl.transform(df, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a76fdd54-a6cf-4155-949f-a60ee8045ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = new_df.dropna(axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da288e26-be7e-475c-b801-ebd3ff5ffe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = processed_df[processed_df.y != -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c4c4b1-2f3c-4bb3-ae7b-be7d37287d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = processed_df[processed_df.y == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b4ea4-2ef8-4c5a-87f3-5cf9892e9765",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e850157-e196-41cc-8e2b-3ca35bcb95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import RFE\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de326ae8-a5a6-4ea4-9c0e-81776ae28f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* fold 1\n",
      "  train X shape : (944058, 33), train y shape : (944058,)\n",
      "  valid X shape : (748769, 33), valid y shape : (748769,)\n",
      "  acc : 0.7427045648380929, auc : 0.803404901338532 \n",
      "\n",
      "* fold 2\n",
      "  train X shape : (1182465, 33), train y shape : (1182465,)\n",
      "  valid X shape : (510362, 33), valid y shape : (510362,)\n",
      "  acc : 0.7477228574158412, auc : 0.8150528336596716 \n",
      "\n",
      "* fold 3\n",
      "  train X shape : (1415144, 33), train y shape : (1415144,)\n",
      "  valid X shape : (277683, 33), valid y shape : (277683,)\n",
      "  acc : 0.7417849840163581, auc : 0.8134406176371771 \n",
      "\n",
      "* fold 4\n",
      "  train X shape : (1576111, 33), train y shape : (1576111,)\n",
      "  valid X shape : (116716, 33), valid y shape : (116716,)\n",
      "  acc : 0.7375960630982877, auc : 0.8160510248725966 \n",
      "\n",
      "* fold 5\n",
      "  train X shape : (1653530, 33), train y shape : (1653530,)\n",
      "  valid X shape : (39297, 33), valid y shape : (39297,)\n",
      "  acc : 0.7363340884467645, auc : 0.8136263977922062 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = train_df[train_df.columns[6:]].drop('y', axis=1).values\n",
    "y = train_df['y'].values\n",
    "\n",
    "fold_acc = []\n",
    "fold_auc = []\n",
    "models = []\n",
    "\n",
    "# split train, valid dataset\n",
    "fold_X = train_df.userID.unique()\n",
    "fold_y = list(train_df.groupby('userID')['y'].apply(lambda x: list(x)[-1]))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds)\n",
    "for fold, (train_id, valid_id) in enumerate(skf.split(fold_X, fold_y)):\n",
    "    train_idx = train_df[train_df.userID.isin(train_id)].index\n",
    "    valid_idx = train_df[train_df.userID.isin(valid_id)].index\n",
    "\n",
    "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "    \n",
    "    print(f'* fold {fold+1}')\n",
    "    print(f'  train X shape : {X_train.shape}, train y shape : {y_train.shape}')\n",
    "    print(f'  valid X shape : {X_valid.shape}, valid y shape : {y_valid.shape}')\n",
    "\n",
    "    \n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "    # training\n",
    "    model = lgb.train(\n",
    "                        {'objective': 'binary'}, \n",
    "                        lgb_train,\n",
    "                        valid_sets=[lgb_train, lgb_valid],\n",
    "                        verbose_eval=100,\n",
    "                        num_boost_round=500,\n",
    "                        early_stopping_rounds=100\n",
    "                    )\n",
    "    models.append(model)\n",
    "\n",
    "    preds = model.predict(X_valid)\n",
    "    \n",
    "    valid_df = pd.DataFrame(train_df[train_df.userID.isin(valid_id)])\n",
    "    valid_df['preds'] = preds\n",
    "    \n",
    "    if y_method == 'last':\n",
    "        cycle_y = valid_df.groupby(y_id)['y'].apply(lambda x: list(x)[0]).values\n",
    "        cycle_preds = valid_df.groupby(y_id)['preds'].mean().values\n",
    "\n",
    "        acc = accuracy_score(cycle_y, np.where(cycle_preds >= 0.5, 1, 0))\n",
    "        auc = roc_auc_score(cycle_y, cycle_preds)\n",
    "    \n",
    "    elif y_method == 'next':\n",
    "        acc = accuracy_score(valid_df.y, np.where(valid_df.preds >= 0.5, 1, 0))\n",
    "        auc = roc_auc_score(valid_df.y, valid_df.preds)\n",
    "        \n",
    "    \n",
    "    print(f'  acc : {acc}, auc : {auc} \\n' )\n",
    "    \n",
    "    fold_acc.append(acc)\n",
    "    fold_auc.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b4dc91-0f04-4b3d-9d09-d42f589f0cc6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4c3f3c2-b0e2-4f16-9023-ce461d7eec62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[test_df.columns[6:]].drop('y', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b490b33-f0e3-47e2-b9d9-769e0100fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "test_preds = []\n",
    "for k in range(len(models)):\n",
    "    temp_df = test_df.copy()\n",
    "    temp_df['preds'] = models[k].predict(X_test)\n",
    "    \n",
    "    if y_method == 'last':\n",
    "        test_pred = temp_df.groupby('userID')['preds'].mean().values\n",
    "    \n",
    "    elif y_method == 'next':\n",
    "        test_pred = temp_df['preds']\n",
    "        \n",
    "    test_preds.append(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f33afd28-b3a5-483b-99b5-37bf4575b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_pred = sum(test_preds) / len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1d9ddcf-c57d-4f4f-8bf4-d2df7c83399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : output/pycaret_lgbm3_['userID', 'testId', 'Retest']_last_5.csv\n"
     ]
    }
   ],
   "source": [
    "# write submission\n",
    "output_dir = 'output/'\n",
    "write_path = os.path.join(output_dir, f\"lgbm_{y_id}_{y_method}_{n_folds}.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)    \n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(final_test_pred):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcca1c-e071-4fc4-a3d6-49c0017d33f2",
   "metadata": {},
   "source": [
    "# Training using Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28a2e1b6-35ef-461d-9564-828955ed5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *\n",
    "from pycaret.utils import check_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82780a-54cc-4d3f-ba38-5a5964a2d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = setup(data=train_df[train_df.columns[6:]], target='y', train_size=0.8, categorical_features=[], numeric_features=list(train_df.columns[6:].drop('y')))\n",
    "\n",
    "lgbm = create_model('lightgbm', sort='AUC')\n",
    "tuned_lgbm = tune_model(lgbm, optimize = 'AUC', fold = 5)\n",
    "final_lgbm = finalize_model(tuned_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2c1ff-a993-4e03-84a5-c6b942c2b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_model(final_lgbm, data=test_df[test_df.columns[6:]].drop('y', axis=1), raw_score=True)\n",
    "total_preds = prediction.Score_1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae253c-0fd0-4392-9dc4-909a20244e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = test_df.copy()\n",
    "temp_df['preds'] = total_preds\n",
    "final_test_pred = temp_df.groupby('userID')['preds'].mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f1140d2-3fa7-41a0-b860-6e60f88553eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference는 위 inference 과정과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7ae9d6-9677-4974-8d06-b7f402962764",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}