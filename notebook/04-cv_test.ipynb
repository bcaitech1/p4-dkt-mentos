{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/\")\n",
    "\n",
    "from fe.agg import (\n",
    "    MakeCorrectCount, \n",
    "    MakeCorrectPercent, \n",
    "    MakeQuestionCount, \n",
    "    MakeTopNCorrectPercent\n",
    ")\n",
    "\n",
    "from fe.seq import (\n",
    "    SplitAssessmentItemID,\n",
    "    MakeFirstClass,\n",
    "    MakeSecondClass,\n",
    "    MakeYMD,\n",
    "    ConvertTime\n",
    ")\n",
    "\n",
    "from dkt_dataset import Preprocess\n",
    "from utils import get_args, get_root_dir\n",
    "from fe.feature import FEPipeline\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "args.root_dir = get_root_dir(\n",
    "    '/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_dir = \"../../input/data/train_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pipeline = FEPipeline(args, [\n",
    "    SplitAssessmentItemID,\n",
    "    ConvertTime,\n",
    "    MakeFirstClass,\n",
    "    MakeSecondClass,\n",
    "    MakeCorrectCount,\n",
    "    MakeQuestionCount,\n",
    "    MakeCorrectPercent,\n",
    "    MakeTopNCorrectPercent\n",
    "])\n",
    "fe_pipeline.debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Descriptions]\n",
      "\n",
      "feature name : base_feature\n",
      "feature type : seq\n",
      " - userID               : 사용자의 고유 번호입니다. 총 7,442명의 학생이 있습니다\n",
      " - assessmentItemID     : 사용자가 푼 문항의 일련 번호입니다.\n",
      " - testID               : 사용자가 푼 문항이 포함된 시험지의 일련 번호입니다.\n",
      " - answerCode           : 사용자가 푼 문항의 정답 여부를 담고 있는 이진 (0/1) 데이터입니다.\n",
      " - Timestamp            : 사용자가 문항을 푼 시간 정보입니다.\n",
      " - KnowledgeTag         : 사용자가 푼 문항의 고유 태그가 담겨져 있습니다.\n",
      "\n",
      "feature name : split_assessmentitem_id\n",
      "feature type : seq\n",
      " - testPaper            : 시험지 번호입니다.\n",
      " - testPaperCnt         : 시험지의 문항 번호입니다.\n",
      "\n",
      "feature name : convert_time\n",
      "feature type : seq\n",
      " - timeSec              : 사용자가 문항을 푼 타임스태프 정보입니다.\n",
      "\n",
      "feature name : make_first_class\n",
      "feature type : seq\n",
      " - firstClass           : 대분류에 해당합니다.\n",
      "\n",
      "feature name : make_second_class\n",
      "feature type : seq\n",
      " - secondClass          : 중분류에 해당합니다.\n",
      "\n",
      "feature name : make_correct_count\n",
      "feature type : agg\n",
      " - correctCnt           : 사용자가 맞춘 문항수를 나타냅니다.\n",
      "\n",
      "feature name : make_question_count\n",
      "feature type : agg\n",
      " - quesCnt              : 사용자가 푼 문항수를 나타냅니다.\n",
      "\n",
      "feature name : make_correct_percent\n",
      "feature type : agg\n",
      " - correctPer           : 사용자가 푼 전체 문항에 대한 정답률입니다.\n",
      "\n",
      "feature name : make_topn_correct_percent\n",
      "feature type : agg\n",
      " - top10CorrectPer      : 사용자가 최근 푼 TOP-10개에 대한 정답률입니다.\n",
      " - top30CorrectPer      : 사용자가 최근 푼 TOP-30개에 대한 정답률입니다.\n",
      " - top50CorrectPer      : 사용자가 최근 푼 TOP-50개에 대한 정답률입니다.\n",
      " - top100CorrectPer     : 사용자가 최근 푼 TOP-100개에 대한 정답률입니다.\n"
     ]
    }
   ],
   "source": [
    "fe_pipeline.description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['userID', 'answerCode', \n",
    "           'testPaper', 'timeSec', 'firstClass', 'secondClass', \n",
    "           'correctPer', 'top10CorrectPer']\n",
    "pre_encoders = {\n",
    "    'label': ['testPaper', 'firstClass', 'secondClass'],\n",
    "    'min_max': ['top10CorrectPer', 'correctPer'],\n",
    "    'std': ['timeSec']\n",
    "}\n",
    "\n",
    "preprocess = Preprocess(args, fe_pipeline, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.feature_engineering()\n",
    "preprocess.split_data()\n",
    "preprocess.preprocessing(pre_encoders)\n",
    "preprocess.data_augmentation(choices=[1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = preprocess.get_data('train_grouped')\n",
    "valid_dataset = preprocess.get_data('valid_grouped')\n",
    "test_dataset = preprocess.get_data('test_grouped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import os.path as p\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ray import tune\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from logger import get_logger\n",
    "from dkt_dataset import DKTDataset\n",
    "from utils import get_args, get_criterion, get_optimizer, get_scheduler, set_seeds\n",
    "\n",
    "\n",
    "class CustomStopper(tune.Stopper):\n",
    "    def __init__(self, args):\n",
    "        self.should_stop = False\n",
    "        self.args = args\n",
    "\n",
    "    def __call__(self, trial_id, result):\n",
    "        if not self.should_stop and result[\"valid_auc\"] > 0.83:\n",
    "            self.should_stop = True\n",
    "\n",
    "        return self.should_stop or result[\"training_iteration\"] >= self.args.n_epochs\n",
    "\n",
    "    def stop_all(self):\n",
    "        return self.should_stop\n",
    "\n",
    "\n",
    "class DKTTrainer:\n",
    "    def __init__(self, args, Model):\n",
    "        self.args = get_args()\n",
    "        self.args.update(**args)\n",
    "        self.create_model = Model\n",
    "\n",
    "        self._helper_init()\n",
    "\n",
    "    def _helper_init(self):\n",
    "        self.prefix_save_path = datetime.now().strftime(\"[%m.%d_%H:%M]\")\n",
    "        self.prefix_save_path = p.join(self.args.root_dir, f\"LOG_{self.prefix_save_path}\")\n",
    "\n",
    "        os.mkdir(self.prefix_save_path)\n",
    "\n",
    "    def _save_config(self, args, filename=\"run_config.json\"):\n",
    "        save_path = p.join(self.prefix_save_path, filename)\n",
    "\n",
    "        with open(save_path, \"w\") as writer:\n",
    "            writer.write(json.dumps(args, indent=4, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    def _get_model(self):\n",
    "        model = self.create_model(self.args).to(self.args.device)\n",
    "        return model\n",
    "\n",
    "    def _update_params(self, loss, model, optimizer):\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), self.args.clip_grad)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    def _collate_fn(self, batches):\n",
    "        \"\"\" key값으로 batch 형성 \"\"\"\n",
    "        new_batches = {k: [] for k in batches[0].keys()}\n",
    "\n",
    "        max_seq_len = 20\n",
    "\n",
    "        # batch의 값들을 각 column끼리 그룹화\n",
    "        for k in batches[0].keys():\n",
    "            for batch in batches:\n",
    "                pre_padded = torch.zeros(max_seq_len)\n",
    "                pre_padded[-len(batch[k]) :] = batch[k]\n",
    "                new_batches[k].append(pre_padded)\n",
    "\n",
    "        for k in batches[0].keys():\n",
    "            new_batches[k] = torch.stack(new_batches[k])\n",
    "\n",
    "        return new_batches\n",
    "\n",
    "    def _get_loaders(self, train_data, valid_data):\n",
    "        trainset = DKTDataset(train_data, self.args, self.args.columns)\n",
    "        validset = DKTDataset(valid_data, self.args, self.args.columns)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            trainset,\n",
    "            num_workers=self.args.num_workers,\n",
    "            shuffle=True,\n",
    "            batch_size=self.args.batch_size,\n",
    "            pin_memory=True,\n",
    "            collate_fn=self._collate_fn,\n",
    "        )\n",
    "\n",
    "        valid_loader = torch.utils.data.DataLoader(\n",
    "            validset,\n",
    "            num_workers=self.args.num_workers,\n",
    "            shuffle=False,\n",
    "            batch_size=self.args.batch_size,\n",
    "            pin_memory=True,\n",
    "            collate_fn=self._collate_fn,\n",
    "        )\n",
    "\n",
    "        return train_loader, valid_loader\n",
    "\n",
    "    def _to_numpy(self, preds):\n",
    "        if self.args.device == \"cuda\":\n",
    "            preds = preds.to(\"cpu\").detach().numpy()\n",
    "        else:  # cpu\n",
    "            preds = preds.detach().numpy()\n",
    "        return preds\n",
    "\n",
    "    def _save_model(self, model, prefix=None):\n",
    "        save_path = p.join(self.args.root_dir, self.prefix_save_path)\n",
    "        assert p.exists(save_path), f\"{save_path} does not exist\"\n",
    "\n",
    "        # get original model if use torch.nn.DataParallel\n",
    "        model = model.module if hasattr(model, \"module\") else model\n",
    "        save_path = f\"{save_path}/{prefix}_model.pth\" if prefix else f\"{save_path}/model.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    def _load_model(self, prefix=None):\n",
    "        load_path = p.join(self.args.root_dir, self.prefix_save_path)\n",
    "        load_path = f\"{load_path}/{prefix}_model.pth\" if prefix else f\"{load_path}/model.pth\"\n",
    "        assert p.exists(load_path), f\"{load_path} does not exist\"\n",
    "\n",
    "        model = self._get_model()\n",
    "        # strict=False, 일치하지 않는 키들을 무시\n",
    "        model.load_state_dict(torch.load(load_path), strict=False)\n",
    "        return model\n",
    "\n",
    "    def _get_metric(self, targets, preds):\n",
    "        auc = roc_auc_score(targets, preds)\n",
    "        acc = accuracy_score(targets, np.where(preds >= 0.5, 1, 0))\n",
    "        return auc, acc\n",
    "\n",
    "    def _compute_loss(self, preds, targets):\n",
    "        loss = get_criterion(preds, targets)\n",
    "\n",
    "        # 마지막 Sequence에 대한 값만 Loss를 계산한다.\n",
    "        loss = loss[:, -1]\n",
    "        loss = torch.mean(loss)\n",
    "        return loss\n",
    "\n",
    "    def _process_batch(self, batch):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _hyper(self, checkpoint_dir):\n",
    "        step = 0\n",
    "        checkpoint_path = p.join(checkpoint_dir, \"checkpoint\")\n",
    "\n",
    "        model = self._get_model()\n",
    "        optimizer = get_optimizer(model, self.args)\n",
    "        scheduler = get_scheduler(optimizer, self.args)\n",
    "\n",
    "        if checkpoint_dir is not None:\n",
    "            checkpoint = torch.load(checkpoint_path)\n",
    "            model.load_state_dict(checkpoint[\"model\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "            step = checkpoint[\"step\"]\n",
    "\n",
    "        while True:\n",
    "            train_auc, train_acc, train_loss = self._train(model, self.train_loader, optimizer)\n",
    "            valid_auc, valid_acc, _, _ = self._validate(model, self.valid_loader)\n",
    "\n",
    "            tune.report(\n",
    "                valid_auc=valid_auc,\n",
    "                valid_acc=valid_acc,\n",
    "                train_auc=train_auc,\n",
    "                train_acc=train_acc,\n",
    "                train_loss=train_loss,\n",
    "            )\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            with tune.checkpoint_dir(step=step) as checkpoint_dir:\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model\": model.state_dict(),\n",
    "                        \"optimizer\": optimizer.state_dict(),\n",
    "                        \"scheduler\": scheduler.state_dict(),\n",
    "                        \"step\": step,\n",
    "                    },\n",
    "                    checkpoint_path,\n",
    "                )\n",
    "\n",
    "    def hyper(self, args, tune_args, train_data, valid_data):\n",
    "        self.train_loader, self.valid_loader = self._get_loaders(train_data, valid_data)\n",
    "\n",
    "        pbt_scheduler = tune.schedulers.PopulationBasedTraining(\n",
    "            time_attr=\"training_iteration\", \n",
    "            **tune_args\n",
    "        )\n",
    "\n",
    "        stopper = CustomStopper(self.args)\n",
    "\n",
    "        analysis = tune.run(\n",
    "            self._hyper,\n",
    "            name=\"pbt_lstm\",\n",
    "            stop=stopper,\n",
    "            max_failures=3,\n",
    "            num_samples=4,\n",
    "            metric=\"\",\n",
    "            scheduler=pbt_scheduler,\n",
    "            keep_checkpoints_num=2,\n",
    "            local_dir=\"~/ray_results\",\n",
    "            checkpoint_score_attr=\"max-valid_auc\",\n",
    "            resources_per_trial={\"cpu\": 3, \"gpu\": 1},\n",
    "            config=self.args,  # custom search algorithm may ignore this\n",
    "        )\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    def _train(self, model, train_loader, optimizer):\n",
    "        model.train()\n",
    "\n",
    "        total_preds, total_targets = [], []\n",
    "        losses = []\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            batch = self._process_batch(batch)\n",
    "            preds = model(batch)\n",
    "            targets = batch[\"answerCode\"]  # correct\n",
    "\n",
    "            loss = self._compute_loss(preds, targets)\n",
    "            self._update_params(loss, model, optimizer)\n",
    "\n",
    "            if step % self.args.log_steps == 0:\n",
    "                print(f\"Training steps: {step} Loss: {str(loss.item())}\")\n",
    "                wandb.log({\"step_train_loss\": loss})\n",
    "\n",
    "            preds, targets = preds[:, -1], targets[:, -1]\n",
    "\n",
    "            if self.args.device == \"cuda\":\n",
    "                preds = preds.to(\"cpu\").detach().numpy()\n",
    "                targets = targets.to(\"cpu\").detach().numpy()\n",
    "            else:\n",
    "                preds = preds.detach().numpy()\n",
    "                targets = targets.detach().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "            total_targets.append(targets)\n",
    "            losses.append(loss)\n",
    "\n",
    "        total_preds = np.concatenate(total_preds)\n",
    "        total_targets = np.concatenate(total_targets)\n",
    "\n",
    "        # Train AUC / ACC\n",
    "        auc, acc = self._get_metric(total_targets, total_preds)\n",
    "        loss_avg = sum(losses) / len(losses)\n",
    "\n",
    "        return auc, acc, loss_avg\n",
    "\n",
    "    def _validate(self, model, valid_loader):\n",
    "        model.eval()\n",
    "\n",
    "        total_preds = []\n",
    "        total_targets = []\n",
    "\n",
    "        for step, batch in enumerate(valid_loader):\n",
    "            batch = self._process_batch(batch)\n",
    "\n",
    "            preds = model(batch)\n",
    "            targets = batch[\"answerCode\"]  # correct\n",
    "\n",
    "            # predictions\n",
    "            preds = preds[:, -1]\n",
    "            targets = targets[:, -1]\n",
    "\n",
    "            if self.args.device == \"cuda\":\n",
    "                preds = preds.to(\"cpu\").detach().numpy()\n",
    "                targets = targets.to(\"cpu\").detach().numpy()\n",
    "            else:  # cpu\n",
    "                preds = preds.detach().numpy()\n",
    "                targets = targets.detach().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "            total_targets.append(targets)\n",
    "\n",
    "        total_preds = np.concatenate(total_preds)\n",
    "        total_targets = np.concatenate(total_targets)\n",
    "\n",
    "        # Train AUC / ACC\n",
    "        auc, acc = self._get_metric(total_targets, total_preds)\n",
    "        print(f\"VALID AUC : {auc} ACC : {acc}\\n\")\n",
    "\n",
    "        return auc, acc, total_preds, total_targets\n",
    "\n",
    "    def _inference(self, test_data, prefix=None):\n",
    "        model = self._load_model(prefix)  # loaded best model to self.model\n",
    "        model.eval()\n",
    "\n",
    "        _, test_loader = self._get_loaders(test_data, test_data)\n",
    "\n",
    "        total_proba_preds = []\n",
    "\n",
    "        for step, batch in enumerate(test_loader):\n",
    "            batch = self._process_batch(batch)\n",
    "\n",
    "            fancy_index = torch.where(batch[\"answerCode\"][:, -1] == -1)\n",
    "            if fancy_index[0].size(0) == 0:\n",
    "                continue\n",
    "\n",
    "            for k in batch.keys():\n",
    "                batch[k] = batch[k][fancy_index]\n",
    "\n",
    "            preds = model(batch)\n",
    "            preds = preds[:, -1]\n",
    "\n",
    "            preds = self._to_numpy(preds)\n",
    "            total_proba_preds += list(preds)\n",
    "\n",
    "        write_path = os.path.join(self.prefix_save_path, f\"{prefix}_test_results.csv\")\n",
    "\n",
    "        with open(write_path, \"w\", encoding=\"utf8\") as w:\n",
    "            w.write(\"id,prediction\\n\")\n",
    "            for idx, proba in enumerate(total_proba_preds):\n",
    "                w.write(f\"{idx},{proba}\\n\")\n",
    "\n",
    "    def debug(self, train_data, valid_data, test_data):\n",
    "        \"\"\"간단한 입,출력을 테스트합니다.\n",
    "        1. Model Summary\n",
    "        3. 한 개 데이터가 잘 생성되는지 체크합니다.\n",
    "        4. 배치 데이터가 잘 생성되는지 체크합니다.\n",
    "        5. forward를 체크합니다.\n",
    "        6. Loss 계산 및, Predict를 체크합니다.\n",
    "        \"\"\"\n",
    "        debug_file_handler = logging.FileHandler(f\"{self.prefix_save_path}/debug.log\")\n",
    "        logger = get_logger(\"debug\")\n",
    "        logger.setLevel(logging.INFO)\n",
    "        logger.addHandler(debug_file_handler)\n",
    "\n",
    "        model = self._get_model()\n",
    "        logger.info(\"MODEl SUMMARY\\n\")\n",
    "        logger.info(summary(model))\n",
    "\n",
    "        logger.info(\"\\nCHECK DATASET\")\n",
    "\n",
    "        for dataset, name in zip([train_data, valid_data, test_data], [\"TRAIN\", \"VALID\", \"TEST\"]):\n",
    "            logger.info(f\"\\n{name} EXAMPLES\")\n",
    "            for column, data in zip(self.args.columns, dataset[0]):\n",
    "                logger.info(f\"{column} : {data[:10]}\")\n",
    "\n",
    "        train_loader, valid_loader = self._get_loaders(train_data, valid_data)\n",
    "        _, test_loader = self._get_loaders(test_data, test_data)\n",
    "\n",
    "        logger.info(\"\\nCHECK BATCH SHAPE\")\n",
    "        for data_loader, name in zip([train_loader, test_loader, valid_loader], [\"TRAIN\", \"TEST\", \"VALID\"]):\n",
    "            batch = next(iter(data_loader))\n",
    "            logger.info(f\"\\n{name} BATCH TYPE : {type(batch)}\")\n",
    "            logger.info(f\"\\n{name} BATCH LEN : {len(batch)}\")\n",
    "            logger.info(f\"\\n{name} BATCH DICT VALUE SHAPE : {batch['answerCode'].shape}\")\n",
    "\n",
    "        logger.info(\"\\nCHECK MODEL FORWARD\")\n",
    "\n",
    "        batch = self._process_batch(batch)\n",
    "        preds = model(batch)\n",
    "\n",
    "        logger.info(f\"\\nPREDS SHAPE: {preds.shape}\")\n",
    "        logger.info(f\"\\nPREDS EXAMPLES: {preds[0]}\")\n",
    "\n",
    "        logger.info(\"\\nCHECK METRICS\")\n",
    "\n",
    "        gt = batch[\"answerCode\"]\n",
    "        loss = self._compute_loss(preds, gt)\n",
    "\n",
    "        logger.info(f\"\\nLOSS : {loss.item()}\")\n",
    "\n",
    "        auc, acc = self._get_metric(self._to_numpy(gt[:, -1]), self._to_numpy(preds[:, -1]))\n",
    "        logger.info(f\"AUC: {auc} ACC: {acc}\")\n",
    "\n",
    "    def run(self, train_data, valid_data, test_data, prefix=\"run\"):\n",
    "        self._save_config(self.args)\n",
    "        set_seeds(self.args.seed)\n",
    "\n",
    "        run_file_handler = logging.FileHandler(f\"{self.prefix_save_path}/{prefix}.log\")\n",
    "        logger = get_logger(\"run\")\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        logger.addHandler(run_file_handler)\n",
    "\n",
    "        model = self._get_model()\n",
    "        wandb.init(project=\"p-stage-4\", reinit=True)\n",
    "        wandb.config.update(self.args)\n",
    "        wandb.watch(model)\n",
    "        wandb.run.name = f\"{self.prefix_save_path}_{prefix}\"\n",
    "\n",
    "        train_loader, valid_loader = self._get_loaders(train_data, valid_data)\n",
    "\n",
    "        self.args.total_steps = int(len(train_loader.dataset) / self.args.batch_size) * (self.args.n_epochs)\n",
    "        self.args.warmup_steps = self.args.total_steps // 10\n",
    "\n",
    "        if self.args.scheduler == \"linear_warmup\":\n",
    "            self.args.scheduler_hp = {\n",
    "                \"num_training_steps\": self.args.total_steps,\n",
    "                \"num_warmup_steps\": self.args.warmup_steps,\n",
    "            }\n",
    "\n",
    "        optimizer = get_optimizer(model, self.args)\n",
    "        scheduler = get_scheduler(optimizer, self.args)\n",
    "\n",
    "        best_auc, best_acc = -1, -1\n",
    "        early_stopping_counter = 0\n",
    "\n",
    "        for epoch in range(self.args.n_epochs):\n",
    "            logger.info(f\"Start Training: Epoch {epoch + 1}\")\n",
    "\n",
    "            train_auc, train_acc, train_loss = self._train(model, train_loader, optimizer)\n",
    "            valid_auc, valid_acc, _, _ = self._validate(model, valid_loader)\n",
    "\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"train_loss\": train_loss,\n",
    "                    \"train_auc\": train_auc,\n",
    "                    \"train_acc\": train_acc,\n",
    "                    \"valid_auc\": valid_auc,\n",
    "                    \"valid_acc\": valid_acc,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            logger.info(f\"TRAIN_LOSS: {train_loss}\")\n",
    "            logger.info(f\"TRAIN AUC: {train_auc} TRAIN ACC: {train_acc}\")\n",
    "            logger.info(f\"VALID AUC: {valid_auc} VALID ACC: {valid_acc}\\n\")\n",
    "\n",
    "            if valid_auc > best_auc:\n",
    "                best_auc, best_acc = valid_auc, valid_acc\n",
    "                self._save_model(model, prefix)\n",
    "                early_stopping_counter = 0\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                logger.info(f\"EarlyStopping counter: {early_stopping_counter}\")\n",
    "                if early_stopping_counter >= self.args.patience:\n",
    "                    logger.info(f\"EarlyStopping counter: {early_stopping_counter} out of {self.args.patience}\")\n",
    "                    break\n",
    "\n",
    "            if self.args.scheduler == \"plateau\":\n",
    "                scheduler.step(best_auc)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "\n",
    "        self._inference(test_data, prefix)\n",
    "        return best_auc, best_acc\n",
    "\n",
    "    def run_cv(self, train_data, valid_data, test_data, test_size:float, folds: int, seeds: list):\n",
    "        assert folds == len(seeds), \"fold와 len(seeds)는 같은 수여야 합니다.\"\n",
    "\n",
    "        total_data = np.concatenate([train_data, valid_data])\n",
    "        self.args.seeds = seeds\n",
    "\n",
    "        valid_results = {}\n",
    "\n",
    "        for n_fold, seed in enumerate(seeds):\n",
    "            self.args.seed = seed\n",
    "            # TODO: User 패턴이 학습이 된다면, 충분히 데이터 유출될 수 있음\n",
    "            train_data, valid_data = train_test_split(total_data, test_size=test_size, random_state=seed)\n",
    "            prefix = f\"cv_{n_fold}\"\n",
    "\n",
    "            best_auc, best_acc = self.run(train_data, valid_data, test_data, prefix=prefix)\n",
    "            valid_results[prefix] = f\"best_auc:{best_auc},best_acc:{best_acc}\"\n",
    "\n",
    "        self._save_config(valid_results, \"valid_cv_results.json\")\n",
    "\n",
    "        new_df = pd.DataFrame([])\n",
    "\n",
    "        for idx in range(folds):\n",
    "            df = pd.read_csv(p.join(self.prefix_save_path, f\"cv_{idx}_test_results.csv\"))\n",
    "\n",
    "            if idx == 0:\n",
    "                new_df[\"id\"] = df[\"id\"]\n",
    "                new_df[\"prediction\"] = df[\"prediction\"]\n",
    "            else:\n",
    "                new_df[\"prediction\"] += df[\"prediction\"]\n",
    "\n",
    "        new_df[\"prediction\"] /= folds\n",
    "        new_df.to_csv(p.join(self.prefix_save_path, \"cv_ensemble_test_results.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, args, hidden_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "\n",
    "        self.args = args\n",
    "        self.device = args.device\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        labels_dim = self.hidden_dim // (len(self.args.n_embeddings) + 1)\n",
    "        interaction_dim = self.hidden_dim - (labels_dim * len(self.args.n_embeddings))\n",
    "\n",
    "        self.embedding_interaction = nn.Embedding(3, interaction_dim)\n",
    "        self.embeddings = nn.ModuleDict(\n",
    "            {k: nn.Embedding(v + 1, labels_dim) for k, v in self.args.n_embeddings.items()}  # plus 1 for padding\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        embed_interaction = self.embedding_interaction(batch[\"interaction\"])\n",
    "        embed = torch.cat(\n",
    "            [embed_interaction] + [self.embeddings[k](batch[k]) for k in self.args.n_embeddings.keys()], 2\n",
    "        )\n",
    "        return embed\n",
    "\n",
    "\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, args, hidden_dim):\n",
    "        super(LinearLayer, self).__init__()\n",
    "\n",
    "        self.args = args\n",
    "        self.device = args.device\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        in_features = len(self.args.n_linears)\n",
    "        self.fc_layer = nn.Linear(in_features, self.hidden_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        cont_v = torch.stack([batch[k] for k in self.args.n_linears]).permute(1, 2, 0)\n",
    "        output = self.fc_layer(cont_v)\n",
    "        return output\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = args.device\n",
    "\n",
    "        self.hidden_dim = self.args.hidden_dim\n",
    "        self.n_layers = self.args.n_layers\n",
    "\n",
    "        self.emb_layer = EmbeddingLayer(args, self.hidden_dim // 2)\n",
    "        self.nli_layer = LinearLayer(args, self.hidden_dim // 2)\n",
    "\n",
    "        self.comb_proj = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim, self.n_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        h = h.to(self.device)\n",
    "\n",
    "        c = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        c = c.to(self.device)\n",
    "\n",
    "        return (h, c)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch_size = batch[\"interaction\"].size(0)\n",
    "\n",
    "        embed = self.emb_layer(batch)\n",
    "        nnbed = self.nli_layer(batch)\n",
    "\n",
    "        embed = torch.cat([embed, nnbed], 2)\n",
    "        X = self.comb_proj(embed)\n",
    "\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.lstm(X, hidden)\n",
    "        out = out.contiguous().view(batch_size, -1, self.hidden_dim)\n",
    "\n",
    "        out = self.fc(out)\n",
    "        preds = self.activation(out).view(batch_size, -1)\n",
    "\n",
    "        return preds\n",
    "\n",
    "    \n",
    "\n",
    "class LSTMTrainer(DKTTrainer):\n",
    "    def _process_batch(self, batch):\n",
    "        batch['mask'] = batch['mask'].type(torch.FloatTensor)\n",
    "        batch['answerCode'] = batch['answerCode'].type(torch.FloatTensor)\n",
    "        batch['correctPer'] = batch['correctPer'].type(torch.FloatTensor)\n",
    "        batch['timeSec'] = batch['timeSec'].type(torch.FloatTensor)\n",
    "\n",
    "        batch['interaction'] = batch['answerCode'] + 1\n",
    "        batch['interaction'] = batch['interaction'].roll(shifts=1, dims=1)\n",
    "        batch['mask'] = batch['mask'].roll(shifts=1, dims=1)\n",
    "        batch['mask'][:, 0] = 0\n",
    "        batch['interaction'] = (batch['interaction'] * batch['mask']).to(torch.int64)\n",
    "\n",
    "        batch['testPaper'] = batch['testPaper'].to(torch.int64)\n",
    "        batch['firstClass'] = batch['firstClass'].to(torch.int64)\n",
    "        batch['secondClass'] = batch['secondClass'].to(torch.int64)\n",
    "        \n",
    "        for k in batch.keys():\n",
    "            batch[k] = batch[k].to(self.args.device)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.columns = columns[1:]\n",
    "args.hidden_dim = 512\n",
    "args.n_epochs = 20\n",
    "args.lr = 0.000144\n",
    "args.batch_size = 60\n",
    "args.n_layers = 2\n",
    "args.weight_decay = 0.00096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = LSTMTrainer(args, LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run_cv(train_dataset, valid_dataset, test_dataset, \n",
    "               test_size=0.5,\n",
    "               folds=5,\n",
    "               seeds=[0, 1, 2, 3, 4]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_result(prefix_path, fold):\n",
    "    print(prefix_path)\n",
    "    file_path = f\"{prefix_path}/valid_cv_results.json\"\n",
    "    total_auc = 0\n",
    "    \n",
    "    with open(file_path, \"r\") as f:\n",
    "        temp = json.load(f)\n",
    "        \n",
    "    for v in temp.values():\n",
    "        print(v)\n",
    "        auc = float(v.split(\",\")[0].split(\":\")[1])\n",
    "        print(auc)\n",
    "        total_auc += auc\n",
    "        \n",
    "    return total_auc / fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=5, test_size=0.5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.08_06:02]\n",
      "best_auc:0.7661859024091989,best_acc:0.7038500506585613\n",
      "0.7661859024091989\n",
      "best_auc:0.7697012223980025,best_acc:0.7083080040526849\n",
      "0.7697012223980025\n",
      "best_auc:0.7695822663689388,best_acc:0.707193515704154\n",
      "0.7695822663689388\n",
      "best_auc:0.766073944882736,best_acc:0.7004052684903749\n",
      "0.766073944882736\n",
      "best_auc:0.7703990192142419,best_acc:0.7065856129685917\n",
      "0.7703990192142419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7683884710546237"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=3, test_size=0.1)**\n",
    "\n",
    "'/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_auc:0.7787203082239915,best_acc:0.7031408308004052\n",
      "0.7787203082239915\n",
      "best_auc:0.7568773386852548,best_acc:0.6930091185410334\n",
      "0.7568773386852548\n",
      "best_auc:0.7832042699233832,best_acc:0.7173252279635258\n",
      "0.7832042699233832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7729339722775431"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=3, test_size=0.2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]\n",
      "best_auc:0.7711663795329549,best_acc:0.7021276595744681\n",
      "0.7711663795329549\n",
      "best_auc:0.7694992957225927,best_acc:0.708966565349544\n",
      "0.7694992957225927\n",
      "best_auc:0.7688831714676145,best_acc:0.705420466058764\n",
      "0.7688831714676145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7698496155743874"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=3, test_size=0.3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]\n",
      "best_auc:0.7716193510849351,best_acc:0.706855791962175\n",
      "0.7716193510849351\n",
      "best_auc:0.7674919575633128,best_acc:0.7007767646065518\n",
      "0.7674919575633128\n",
      "best_auc:0.7670384501490044,best_acc:0.707531239446133\n",
      "0.7670384501490044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7687165862657507"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=5, test_size=0.1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]\n",
      "best_auc:0.7787203082239915,best_acc:0.7031408308004052\n",
      "0.7787203082239915\n",
      "best_auc:0.7568773386852548,best_acc:0.6930091185410334\n",
      "0.7568773386852548\n",
      "best_auc:0.7832042699233832,best_acc:0.7173252279635258\n",
      "0.7832042699233832\n",
      "best_auc:0.763088549745266,best_acc:0.6990881458966566\n",
      "0.763088549745266\n",
      "best_auc:0.7603983572895276,best_acc:0.7001013171225937\n",
      "0.7603983572895276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7684577647734846"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=5, test_size=0.2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]\n",
      "best_auc:0.7711662510614954,best_acc:0.7021276595744681\n",
      "0.7711662510614954\n",
      "best_auc:0.7694992957225927,best_acc:0.708966565349544\n",
      "0.7694992957225927\n",
      "best_auc:0.7688831714676148,best_acc:0.705420466058764\n",
      "0.7688831714676148\n",
      "best_auc:0.7611421154394541,best_acc:0.7008611955420466\n",
      "0.7611421154394541\n",
      "best_auc:0.7683923069322051,best_acc:0.7031408308004052\n",
      "0.7683923069322051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7678166281246723"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=5, test_size=0.3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]\n",
      "best_auc:0.7716193510849351,best_acc:0.706855791962175\n",
      "0.7716193510849351\n",
      "best_auc:0.7674919575633128,best_acc:0.7007767646065518\n",
      "0.7674919575633128\n",
      "best_auc:0.7670384501490044,best_acc:0.707531239446133\n",
      "0.7670384501490044\n",
      "best_auc:0.761875755153294,best_acc:0.698919284025667\n",
      "0.761875755153294\n",
      "best_auc:0.7712231208940146,best_acc:0.7060114826072272\n",
      "0.7712231208940146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7678497269689121"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=10, test_size=0.1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]\n",
      "best_auc:0.7787203082239915,best_acc:0.7031408308004052\n",
      "0.7787203082239915\n",
      "best_auc:0.7568773386852548,best_acc:0.6930091185410334\n",
      "0.7568773386852548\n",
      "best_auc:0.7832042699233832,best_acc:0.7173252279635258\n",
      "0.7832042699233832\n",
      "best_auc:0.763088549745266,best_acc:0.6990881458966566\n",
      "0.763088549745266\n",
      "best_auc:0.7603983572895276,best_acc:0.7001013171225937\n",
      "0.7603983572895276\n",
      "best_auc:0.7687280830111568,best_acc:0.7102330293819655\n",
      "0.7687280830111568\n",
      "best_auc:0.7894953798767967,best_acc:0.7264437689969605\n",
      "0.7894953798767967\n",
      "best_auc:0.7855520736077601,best_acc:0.7137791286727457\n",
      "0.7855520736077601\n",
      "best_auc:0.7867072490505839,best_acc:0.7137791286727457\n",
      "0.7867072490505839\n",
      "best_auc:0.76207450000411,best_acc:0.7036474164133738\n",
      "0.76207450000411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.773484610941783"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=10, test_size=0.2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]\n",
      "best_auc:0.7711662510614954,best_acc:0.7021276595744681\n",
      "0.7711662510614954\n",
      "best_auc:0.7694992957225927,best_acc:0.708966565349544\n",
      "0.7694992957225927\n",
      "best_auc:0.7688831714676145,best_acc:0.705420466058764\n",
      "0.7688831714676145\n",
      "best_auc:0.761142115439454,best_acc:0.7008611955420466\n",
      "0.761142115439454\n",
      "best_auc:0.7683923069322051,best_acc:0.7031408308004052\n",
      "0.7683923069322051\n",
      "best_auc:0.772597449538329,best_acc:0.7102330293819655\n",
      "0.772597449538329\n",
      "best_auc:0.7781345440173286,best_acc:0.7193515704154002\n",
      "0.7781345440173286\n",
      "best_auc:0.7746736038092428,best_acc:0.7074468085106383\n",
      "0.7746736038092428\n",
      "best_auc:0.7780290602025899,best_acc:0.7079533941236069\n",
      "0.7780290602025899\n",
      "best_auc:0.7647608510883205,best_acc:0.7084599797365755\n",
      "0.7647608510883205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7707278649279171"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(folds=10, test_size=0.3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]\n",
      "best_auc:0.7716193510849351,best_acc:0.706855791962175\n",
      "0.7716193510849351\n",
      "best_auc:0.7674919575633128,best_acc:0.7007767646065518\n",
      "0.7674919575633128\n",
      "best_auc:0.7670384501490044,best_acc:0.707531239446133\n",
      "0.7670384501490044\n",
      "best_auc:0.761875755153294,best_acc:0.698919284025667\n",
      "0.761875755153294\n",
      "best_auc:0.7712231208940146,best_acc:0.7060114826072272\n",
      "0.7712231208940146\n",
      "best_auc:0.7697955602890236,best_acc:0.7012833502195205\n",
      "0.7697955602890236\n",
      "best_auc:0.7769459937007558,best_acc:0.7102330293819655\n",
      "0.7769459937007558\n",
      "best_auc:0.7756501346153429,best_acc:0.7051671732522796\n",
      "0.7756501346153429\n",
      "best_auc:0.7749429001964473,best_acc:0.704322863897332\n",
      "0.7749429001964473\n",
      "best_auc:0.7714736603336819,best_acc:0.7066869300911854\n",
      "0.7714736603336819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7708056883979812"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result(trainer.prefix_save_path, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"../models/lstm/hyper_test/LOG_[06.07_16:15]/cv_ensemble_test_results.csv\",\n",
    "    index_col=['Unnamed: 0']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.589862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.594878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.262907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.788662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.433151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  prediction\n",
       "0   0    0.589862\n",
       "1   1    0.594878\n",
       "2   2    0.262907\n",
       "3   3    0.788662\n",
       "4   4    0.433151"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/j-gunmo/desktop/00.my-project/17.P-Stage-T1003/4-STAGE/models/lstm/hyper_test/LOG_[06.07_16:15]'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.prefix_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    \"../models/lstm/hyper_test/LOG_[06.07_16:15]/cv_ensembles_test_results.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline_code",
   "language": "python",
   "name": "baseline_code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
