{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2bbe9fb-a044-42b5-a2dc-1113f78c21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('/opt/ml/develop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c79f721a-ca32-468c-a93b-24c8f9285071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from args_jupyter import parse_args\n",
    "from dkt.dataloader import Preprocess\n",
    "from dkt import trainer\n",
    "from dkt.utils import setSeeds\n",
    "from dkt.dataloader import get_loaders\n",
    "from dkt.optimizer import get_optimizer, get_lr\n",
    "from dkt.scheduler import get_scheduler\n",
    "from dkt.criterion import get_criterion\n",
    "from dkt.metric import get_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87ceefac-0a8b-461c-9fae-0925033a422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args(mode='train')\n",
    "setSeeds(args.seed)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0cf579-64e8-4947-98a5-40cdf6894107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배치 전처리\n",
    "def process_batch(batch, args):\n",
    "\n",
    "    test, question, tag, correct, mask = batch\n",
    "    \n",
    "    \n",
    "    # change to float\n",
    "    mask = mask.type(torch.FloatTensor)\n",
    "    correct = correct.type(torch.FloatTensor)\n",
    "\n",
    "    #  interaction을 임시적으로 correct를 한칸 우측으로 이동한 것으로 사용\n",
    "    #    saint의 경우 decoder에 들어가는 input이다\n",
    "    interaction = correct + 1 # 패딩을 위해 correct값에 1을 더해준다.\n",
    "    interaction = interaction.roll(shifts=1, dims=1)\n",
    "    interaction[:, 0] = 0 # set padding index to the first sequence\n",
    "    interaction = (interaction * mask).to(torch.int64)\n",
    "    # print(interaction)\n",
    "    # exit()\n",
    "    #  test_id, question_id, tag\n",
    "    test = ((test + 1) * mask).to(torch.int64)\n",
    "    question = ((question + 1) * mask).to(torch.int64)\n",
    "    tag = ((tag + 1) * mask).to(torch.int64)\n",
    "\n",
    "    # gather index\n",
    "    # 마지막 sequence만 사용하기 위한 index\n",
    "    gather_index = torch.tensor(np.count_nonzero(mask, axis=1))\n",
    "    gather_index = gather_index.view(-1, 1) - 1\n",
    "\n",
    "\n",
    "    # device memory로 이동\n",
    "\n",
    "    test = test.to(args.device)\n",
    "    question = question.to(args.device)\n",
    "\n",
    "\n",
    "    tag = tag.to(args.device)\n",
    "    correct = correct.to(args.device)\n",
    "    mask = mask.to(args.device)\n",
    "\n",
    "    interaction = interaction.to(args.device)\n",
    "    gather_index = gather_index.to(args.device)\n",
    "\n",
    "    return (test, question,\n",
    "            tag, correct, mask,\n",
    "            interaction, gather_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eacf9b0a-4389-4f84-8000-2deae51fc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(\n",
    "            0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.scale * self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a04ef2d-a666-4c95-a95d-f9043a368af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocess(args)\n",
    "preprocess.load_train_data(args.file_name)\n",
    "train_data = preprocess.get_train_data()\n",
    "\n",
    "train_data, valid_data = preprocess.split_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bf1672-12da-4592-8a6d-d8bc24c02856",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = get_loaders(args, train_data, valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2140465-5ef1-4657-a0c2-5bfe039ef9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testID size: torch.Size([64, 20])\n",
      "assessmentItemId size: torch.Size([64, 20])\n",
      "knowledgetag size: torch.Size([64, 20])\n",
      "answercode size: torch.Size([64, 20])\n",
      "mask size: torch.Size([64, 20])\n"
     ]
    }
   ],
   "source": [
    "batch = None\n",
    "for t in train_loader:\n",
    "    # train_loader is tuple\n",
    "    \n",
    "    print(f\"testID size: {t[0].size()}\")\n",
    "    print(f\"assessmentItemId size: {t[1].size()}\")\n",
    "    print(f\"knowledgetag size: {t[2].size()}\")\n",
    "    print(f\"answercode size: {t[3].size()}\")\n",
    "    print(f\"mask size: {t[4].size()}\")\n",
    "    \n",
    "    batch = t\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a87d848-cb61-4a16-890d-35a3ce19dcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(asset_dir='asset/', batch_size=64, clip_grad=10, data_dir='/opt/ml/input/data/train_dataset', data_id='userID', device='cpu', drop_out=0.2, emb_size=100, file_name='train_data.csv', hidden_dim=64, log_steps=50, lr=0.0001, max_lr=0.0001, max_seq_len=20, min_lr=1e-05, model='lstm', model_dir='models/', model_name='model.pt', n_epochs=20, n_heads=2, n_layers=2, n_questions=9455, n_tag=913, n_test=1538, num_workers=1, optimizer='adam', output_dir='output/', patience=5, scheduler='plateau', scheduler_step=5, seed=5, test_file_name='test_data.csv', wandb_name=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda08c9c-e1e9-4aee-aff0-4ccd0c56dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import copy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3e1585-22f2-4b9a-87ec-ad26905fa93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = process_batch(batch, args)\n",
    "# test, question, tag, correct, mask, interaction, gather_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72c3bcbc-837b-4a83-ac92-18c95e79cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test, question, tag, _, mask, interaction, _ = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43e718b0-ed26-4da7-996d-6bf952166c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = interaction.size(0)\n",
    "seq_len = interaction.size(1)\n",
    "batch_size, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d214bd30-2ab1-432b-be18-5dcc6756f82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c9b0a30-a7de-4861-8d1d-7e4587593b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "313a1671-4823-45f0-8610-0e5ea99cccac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1, temp2 = mask.view(args.batch_size, args.max_seq_len, -1).max(2)\n",
    "temp1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ce945-0d56-4eb1-be55-96acc4c7506f",
   "metadata": {},
   "source": [
    "# Saint 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4aac822-3047-40d8-aa7e-189d8cdc1464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 20, 21])\n",
      "torch.Size([64, 20, 21])\n",
      "torch.Size([64, 20, 21])\n"
     ]
    }
   ],
   "source": [
    "embedding_test = nn.Embedding(args.n_test + 1, args.hidden_dim//3)\n",
    "embedding_question = nn.Embedding(args.n_questions + 1, args.hidden_dim//3)\n",
    "embedding_tag = nn.Embedding(args.n_tag + 1, args.hidden_dim//3)\n",
    "\n",
    "embed_test = embedding_test(test)\n",
    "embed_question = embedding_question(question)\n",
    "embed_tag = embedding_tag(tag)\n",
    "\n",
    "print(embed_test.size())\n",
    "print(embed_question.size())\n",
    "print(embed_tag.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe284d31-895d-479b-9d74-689b944e0562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 63])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_enc = torch.cat([embed_test,\n",
    "                       embed_question,\n",
    "                       embed_tag,], 2)\n",
    "\n",
    "embed_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f03a5f2-74d5-4cb3-b6d7-fc00d56b9b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_comb_proj = nn.Linear((args.hidden_dim//3)*3, args.hidden_dim)\n",
    "embed_enc = enc_comb_proj(embed_enc)\n",
    "embed_enc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e274b61-2a9a-44be-80f0-6f31768f5fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5263,  0.9159,  1.7554,  ...,  0.6618, -1.7855,  0.6752],\n",
       "         [ 1.5263,  0.9159,  1.7554,  ...,  0.6618, -1.7855,  0.6752],\n",
       "         [ 1.5263,  0.9159,  1.7554,  ...,  0.6618, -1.7855,  0.6752],\n",
       "         ...,\n",
       "         [ 0.3263,  0.9922,  1.2015,  ...,  1.0176, -0.6821,  2.5479],\n",
       "         [ 0.3263,  0.9922,  1.2015,  ...,  1.0176, -0.6821,  2.5479],\n",
       "         [ 0.3263,  0.9922,  1.2015,  ...,  1.0176, -0.6821,  2.5479]],\n",
       "\n",
       "        [[-1.0275, -0.2720,  0.1552,  ..., -2.3512,  1.2479,  1.6195],\n",
       "         [-1.0275, -0.2720,  0.1552,  ..., -2.3512,  1.2479,  1.6195],\n",
       "         [-1.0275, -0.2720,  0.1552,  ..., -2.3512,  1.2479,  1.6195],\n",
       "         ...,\n",
       "         [ 0.7609, -1.5030,  1.5665,  ...,  0.5125, -0.7370, -2.5342],\n",
       "         [ 0.7609, -1.5030,  1.5665,  ...,  0.5125, -0.7370, -2.5342],\n",
       "         [ 0.7609, -1.5030,  1.5665,  ...,  0.5125, -0.7370, -2.5342]],\n",
       "\n",
       "        [[-1.6326,  1.1773, -0.2609,  ...,  1.1532, -1.4429,  1.3231],\n",
       "         [-1.6326,  1.1773, -0.2609,  ...,  1.1532, -1.4429,  1.3231],\n",
       "         [-1.6326,  1.1773, -0.2609,  ...,  1.1532, -1.4429,  1.3231],\n",
       "         ...,\n",
       "         [-1.5165,  1.3687,  0.1026,  ...,  1.6350, -0.8285,  0.9357],\n",
       "         [-1.5165,  1.3687,  0.1026,  ...,  1.6350, -0.8285,  0.9357],\n",
       "         [-1.5165,  1.3687,  0.1026,  ...,  1.6350, -0.8285,  0.9357]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4270,  0.0256, -0.3357,  ..., -1.0681, -1.6861, -1.0542],\n",
       "         [ 0.4270,  0.0256, -0.3357,  ..., -1.0681, -1.6861, -1.0542],\n",
       "         [ 0.4270,  0.0256, -0.3357,  ..., -1.0681, -1.6861, -1.0542],\n",
       "         ...,\n",
       "         [ 0.5993, -0.7873, -1.4123,  ..., -0.0898, -1.3445, -1.9726],\n",
       "         [ 0.5993, -0.7873, -1.4123,  ..., -0.0898, -1.3445, -1.9726],\n",
       "         [ 0.5993, -0.7873, -1.4123,  ..., -0.0898, -1.3445, -1.9726]],\n",
       "\n",
       "        [[-1.5880, -0.2614, -1.4178,  ...,  1.2623,  0.4606, -0.5076],\n",
       "         [-1.5880, -0.2614, -1.4178,  ...,  1.2623,  0.4606, -0.5076],\n",
       "         [-1.5880, -0.2614, -1.4178,  ...,  1.2623,  0.4606, -0.5076],\n",
       "         ...,\n",
       "         [-0.3573, -0.0692, -0.0558,  ..., -1.1633,  0.2750,  0.0374],\n",
       "         [-0.3573, -0.0692, -0.0558,  ..., -1.1633,  0.2750,  0.0374],\n",
       "         [-0.3573, -0.0692, -0.0558,  ..., -1.1633,  0.2750,  0.0374]],\n",
       "\n",
       "        [[ 0.7866, -1.1976,  1.0860,  ...,  1.4569, -0.1013,  1.4850],\n",
       "         [ 0.7866, -1.1976,  1.0860,  ...,  1.4569, -0.1013,  1.4850],\n",
       "         [ 0.7866, -1.1976,  1.0860,  ...,  1.4569, -0.1013,  1.4850],\n",
       "         ...,\n",
       "         [ 1.6584, -0.9227, -1.4030,  ...,  1.2422, -0.0211,  0.2089],\n",
       "         [ 1.6584, -0.9227, -1.4030,  ...,  1.2422, -0.0211,  0.2089],\n",
       "         [ 1.6584, -0.9227, -1.4030,  ...,  1.2422, -0.0211,  0.2089]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f578c71-fe63-40d4-bad8-d49b1764fe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 20, 21])\n",
      "torch.Size([64, 20, 21])\n",
      "torch.Size([64, 20, 21])\n",
      "torch.Size([64, 20, 21])\n"
     ]
    }
   ],
   "source": [
    "# DECODER embedding# interaction은 현재 correct으로 구성되어있다. correct(1, 2) + padding(0)\n",
    "embedding_interaction = nn.Embedding(3, args.hidden_dim//3)\n",
    "\n",
    "embed_test = embedding_test(test)\n",
    "embed_question = embedding_question(question)\n",
    "embed_tag = embedding_tag(tag)\n",
    "embed_interaction = embedding_interaction(interaction)\n",
    "\n",
    "print(embed_test.size())\n",
    "print(embed_question.size())\n",
    "print(embed_tag.size())\n",
    "print(embed_interaction.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32bc853e-3dfd-402b-8db4-78c941ddb452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5263,  0.9159,  1.7554,  ...,  0.6618, -1.7855,  0.6752],\n",
       "         [ 1.5263,  0.9159,  1.7554,  ...,  0.6618, -1.7855,  0.6752],\n",
       "         [ 1.5263,  0.9159,  1.7554,  ...,  0.6618, -1.7855,  0.6752],\n",
       "         ...,\n",
       "         [ 0.3263,  0.9922,  1.2015,  ...,  1.0176, -0.6821,  2.5479],\n",
       "         [ 0.3263,  0.9922,  1.2015,  ...,  1.0176, -0.6821,  2.5479],\n",
       "         [ 0.3263,  0.9922,  1.2015,  ...,  1.0176, -0.6821,  2.5479]],\n",
       "\n",
       "        [[-1.0275, -0.2720,  0.1552,  ..., -2.3512,  1.2479,  1.6195],\n",
       "         [-1.0275, -0.2720,  0.1552,  ..., -2.3512,  1.2479,  1.6195],\n",
       "         [-1.0275, -0.2720,  0.1552,  ..., -2.3512,  1.2479,  1.6195],\n",
       "         ...,\n",
       "         [ 0.7609, -1.5030,  1.5665,  ...,  0.5125, -0.7370, -2.5342],\n",
       "         [ 0.7609, -1.5030,  1.5665,  ...,  0.5125, -0.7370, -2.5342],\n",
       "         [ 0.7609, -1.5030,  1.5665,  ...,  0.5125, -0.7370, -2.5342]],\n",
       "\n",
       "        [[-1.6326,  1.1773, -0.2609,  ...,  1.1532, -1.4429,  1.3231],\n",
       "         [-1.6326,  1.1773, -0.2609,  ...,  1.1532, -1.4429,  1.3231],\n",
       "         [-1.6326,  1.1773, -0.2609,  ...,  1.1532, -1.4429,  1.3231],\n",
       "         ...,\n",
       "         [-1.5165,  1.3687,  0.1026,  ...,  1.6350, -0.8285,  0.9357],\n",
       "         [-1.5165,  1.3687,  0.1026,  ...,  1.6350, -0.8285,  0.9357],\n",
       "         [-1.5165,  1.3687,  0.1026,  ...,  1.6350, -0.8285,  0.9357]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4270,  0.0256, -0.3357,  ..., -1.0681, -1.6861, -1.0542],\n",
       "         [ 0.4270,  0.0256, -0.3357,  ..., -1.0681, -1.6861, -1.0542],\n",
       "         [ 0.4270,  0.0256, -0.3357,  ..., -1.0681, -1.6861, -1.0542],\n",
       "         ...,\n",
       "         [ 0.5993, -0.7873, -1.4123,  ..., -0.0898, -1.3445, -1.9726],\n",
       "         [ 0.5993, -0.7873, -1.4123,  ..., -0.0898, -1.3445, -1.9726],\n",
       "         [ 0.5993, -0.7873, -1.4123,  ..., -0.0898, -1.3445, -1.9726]],\n",
       "\n",
       "        [[-1.5880, -0.2614, -1.4178,  ...,  1.2623,  0.4606, -0.5076],\n",
       "         [-1.5880, -0.2614, -1.4178,  ...,  1.2623,  0.4606, -0.5076],\n",
       "         [-1.5880, -0.2614, -1.4178,  ...,  1.2623,  0.4606, -0.5076],\n",
       "         ...,\n",
       "         [-0.3573, -0.0692, -0.0558,  ..., -1.1633,  0.2750,  0.0374],\n",
       "         [-0.3573, -0.0692, -0.0558,  ..., -1.1633,  0.2750,  0.0374],\n",
       "         [-0.3573, -0.0692, -0.0558,  ..., -1.1633,  0.2750,  0.0374]],\n",
       "\n",
       "        [[ 0.7866, -1.1976,  1.0860,  ...,  1.4569, -0.1013,  1.4850],\n",
       "         [ 0.7866, -1.1976,  1.0860,  ...,  1.4569, -0.1013,  1.4850],\n",
       "         [ 0.7866, -1.1976,  1.0860,  ...,  1.4569, -0.1013,  1.4850],\n",
       "         ...,\n",
       "         [ 1.6584, -0.9227, -1.4030,  ...,  1.2422, -0.0211,  0.2089],\n",
       "         [ 1.6584, -0.9227, -1.4030,  ...,  1.2422, -0.0211,  0.2089],\n",
       "         [ 1.6584, -0.9227, -1.4030,  ...,  1.2422, -0.0211,  0.2089]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7e41360-c154-48a6-b200-5741afc8fb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 64])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dec = torch.cat([embed_test,\n",
    "                       embed_question,\n",
    "                       embed_tag,\n",
    "                       embed_interaction], 2)\n",
    "\n",
    "# decoder combination projection\n",
    "dec_comb_proj = nn.Linear((args.hidden_dim//3)*4, args.hidden_dim)\n",
    "\n",
    "embed_dec = dec_comb_proj(embed_dec)\n",
    "embed_dec.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dafc45fc-a15b-4bc3-9297-4a03bc5efe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_mask = None\n",
    "dec_mask = None\n",
    "enc_dec_mask = None\n",
    "\n",
    "def get_mask(seq_len):\n",
    "        mask = torch.from_numpy(np.triu(np.ones((seq_len, seq_len)), k=1))\n",
    "\n",
    "        return mask.masked_fill(mask==1, float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9315f739-7f42-457f-9d50-0449ee68905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ATTENTION MASK 생성\n",
    "# encoder하고 decoder의 mask는 가로 세로 길이가 모두 동일하여\n",
    "# 사실 이렇게 3개로 나눌 필요가 없다\n",
    "\n",
    "enc_mask = get_mask(seq_len)\n",
    "print(enc_mask.size())\n",
    "enc_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b28a577-1fd9-408d-9f08-e8fffc5a3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enc_mask is None or enc_mask.size(0) != seq_len:\n",
    "    enc_mask = get_mask(seq_len)\n",
    "\n",
    "if dec_mask is None or dec_mask.size(0) != seq_len:\n",
    "    dec_mask = get_mask(seq_len)\n",
    "\n",
    "if enc_dec_mask is None or enc_dec_mask.size(0) != seq_len:\n",
    "    enc_dec_mask = get_mask(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a12b8fc-3b68-4259-8158-575b7cde0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_enc = embed_enc.permute(1, 0, 2)\n",
    "embed_dec = embed_dec.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "579e8bf9-3bdb-4ef2-928b-fc1b0a1c8537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 64, 64]), torch.Size([20, 64, 64]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_enc.size(), embed_dec.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "163938ba-5deb-417b-aac8-5f7872ada5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 64, 64]), torch.Size([20, 64, 64]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positional encoding\n",
    "pos_encoder = PositionalEncoding(args.hidden_dim, args.drop_out, args.max_seq_len)\n",
    "pos_decoder = PositionalEncoding(args.hidden_dim, args.drop_out, args.max_seq_len)\n",
    "\n",
    "# Positional encoding\n",
    "embed_enc = pos_encoder(embed_enc)\n",
    "embed_dec = pos_decoder(embed_dec)\n",
    "\n",
    "embed_enc.size(), embed_dec.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a11f4a4-db64-4dae-a957-4827bc8fe9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = nn.Transformer(\n",
    "            d_model=args.hidden_dim, \n",
    "            nhead=args.n_heads,\n",
    "            num_encoder_layers=args.n_layers, \n",
    "            num_decoder_layers=args.n_layers, \n",
    "            dim_feedforward=args.hidden_dim, \n",
    "            dropout=args.drop_out, \n",
    "            activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a9a39f7-ec8e-43c4-b525-9e6813b11a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 64, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = transformer(embed_enc, embed_dec,\n",
    "                 src_mask=enc_mask,\n",
    "                 tgt_mask=dec_mask,\n",
    "                 memory_mask=enc_dec_mask)\n",
    "\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7b42e9b-f157-4859-8de4-5bbfe47c1fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = out.contiguous().view(batch_size, -1, args.hidden_dim)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed7b4319-8c63-4ad5-afe8-7e1e68771409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(args.hidden_dim, 1)\n",
    "activation = nn.Sigmoid()\n",
    "\n",
    "out = fc(out)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc7e8073-8b34-4417-995f-ee7173ed9a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = activation(out).view(batch_size, -1)\n",
    "preds.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2d5a0-3aa8-4039-8472-627533d782ef",
   "metadata": {},
   "source": [
    "\n",
    "# 클래스로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3aef925-3d3b-480c-b5aa-55e9bd298492",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows_per_step = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5414c2d1-d341-49e0-9ed7-aef8cdad3bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(\n",
    "            0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.scale * self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Saint(nn.Module):\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super(Saint, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = args.device\n",
    "\n",
    "        self.hidden_dim = self.args.hidden_dim\n",
    "        # self.dropout = self.args.dropout\n",
    "        self.dropout = 0.\n",
    "        \n",
    "        ### Embedding \n",
    "        # ENCODER embedding\n",
    "        self.embedding_test = nn.Embedding(self.args.n_test + 1, self.hidden_dim//3)\n",
    "        self.embedding_question = nn.Embedding(self.args.n_questions + 1, self.hidden_dim//3)\n",
    "        self.embedding_tag = nn.Embedding(self.args.n_tag + 1, self.hidden_dim//3)\n",
    "        \n",
    "        # encoder combination projection\n",
    "        self.enc_comb_proj = nn.Linear((self.hidden_dim//3)*3, self.hidden_dim)\n",
    "\n",
    "        # DECODER embedding\n",
    "        # interaction은 현재 correct으로 구성되어있다. correct(1, 2) + padding(0)\n",
    "        self.embedding_interaction = nn.Embedding(3, self.hidden_dim//3)\n",
    "        \n",
    "        # decoder combination projection\n",
    "        self.dec_comb_proj = nn.Linear((self.hidden_dim//3)*4, self.hidden_dim)\n",
    "\n",
    "        # Positional encoding\n",
    "        self.pos_encoder = PositionalEncoding(self.hidden_dim, self.dropout, self.args.max_seq_len)\n",
    "        self.pos_decoder = PositionalEncoding(self.hidden_dim, self.dropout, self.args.max_seq_len)\n",
    "        \n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=self.hidden_dim, \n",
    "            nhead=self.args.n_heads,\n",
    "            num_encoder_layers=self.args.n_layers, \n",
    "            num_decoder_layers=self.args.n_layers, \n",
    "            dim_feedforward=self.hidden_dim, \n",
    "            dropout=self.dropout, \n",
    "            activation='relu')\n",
    "\n",
    "        self.fc = nn.Linear(self.hidden_dim, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        self.enc_mask = None\n",
    "        self.dec_mask = None\n",
    "        self.enc_dec_mask = None\n",
    "    \n",
    "    def get_mask(self, seq_len):\n",
    "        mask = torch.from_numpy(np.triu(np.ones((seq_len, seq_len)), k=1))\n",
    "\n",
    "        return mask.masked_fill(mask==1, float('-inf'))\n",
    "\n",
    "    def forward(self, input):\n",
    "        test, question, tag, _, mask, interaction, _ = input\n",
    "\n",
    "        batch_size = interaction.size(0)\n",
    "        seq_len = interaction.size(1)\n",
    "\n",
    "        # 신나는 embedding\n",
    "        # ENCODER\n",
    "        embed_test = self.embedding_test(test)\n",
    "        embed_question = self.embedding_question(question)\n",
    "        embed_tag = self.embedding_tag(tag)\n",
    "\n",
    "        embed_enc = torch.cat([embed_test,\n",
    "                               embed_question,\n",
    "                               embed_tag,], 2)\n",
    "\n",
    "        embed_enc = self.enc_comb_proj(embed_enc)\n",
    "        \n",
    "        # DECODER     \n",
    "        embed_test = self.embedding_test(test)\n",
    "        embed_question = self.embedding_question(question)\n",
    "        embed_tag = self.embedding_tag(tag)\n",
    "\n",
    "        embed_interaction = self.embedding_interaction(interaction)\n",
    "\n",
    "        embed_dec = torch.cat([embed_test,\n",
    "                               embed_question,\n",
    "                               embed_tag,\n",
    "                               embed_interaction], 2)\n",
    "\n",
    "        embed_dec = self.dec_comb_proj(embed_dec)\n",
    "\n",
    "        # ATTENTION MASK 생성\n",
    "        # encoder하고 decoder의 mask는 가로 세로 길이가 모두 동일하여\n",
    "        # 사실 이렇게 3개로 나눌 필요가 없다\n",
    "        if self.enc_mask is None or self.enc_mask.size(0) != seq_len:\n",
    "            self.enc_mask = self.get_mask(seq_len).to(self.device)\n",
    "            \n",
    "        if self.dec_mask is None or self.dec_mask.size(0) != seq_len:\n",
    "            self.dec_mask = self.get_mask(seq_len).to(self.device)\n",
    "            \n",
    "        if self.enc_dec_mask is None or self.enc_dec_mask.size(0) != seq_len:\n",
    "            self.enc_dec_mask = self.get_mask(seq_len).to(self.device)\n",
    "            \n",
    "  \n",
    "        embed_enc = embed_enc.permute(1, 0, 2)\n",
    "        embed_dec = embed_dec.permute(1, 0, 2)\n",
    "        \n",
    "        # Positional encoding\n",
    "        embed_enc = self.pos_encoder(embed_enc)\n",
    "        embed_dec = self.pos_decoder(embed_dec)\n",
    "        \n",
    "        out = self.transformer(embed_enc, embed_dec,\n",
    "                               src_mask=self.enc_mask,\n",
    "                               tgt_mask=self.dec_mask,\n",
    "                               memory_mask=self.enc_dec_mask)\n",
    "\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = out.contiguous().view(batch_size, -1, self.hidden_dim)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        preds = self.activation(out).view(batch_size, -1)\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36453413-1e9f-4acb-93b0-bbdab56cf726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size : torch.Size([64, 20])\n"
     ]
    }
   ],
   "source": [
    "model = Saint(args)\n",
    "\n",
    "for step, batch in enumerate(train_loader):\n",
    "    inputs = process_batch(batch, args)\n",
    "    output = model(inputs)\n",
    "    print(f\"output size : {output.size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "612c0e54-8f46-4422-8395-56624cad5f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2362, 0.2398, 0.2560,  ..., 0.4950, 0.3964, 0.3946],\n",
       "        [0.3345, 0.1979, 0.2174,  ..., 0.4468, 0.4816, 0.4916],\n",
       "        [0.2613, 0.2527, 0.3043,  ..., 0.3738, 0.3584, 0.3135],\n",
       "        ...,\n",
       "        [0.3734, 0.3503, 0.3339,  ..., 0.3717, 0.3900, 0.3282],\n",
       "        [0.2320, 0.2227, 0.2540,  ..., 0.4059, 0.4327, 0.3781],\n",
       "        [0.2846, 0.4026, 0.4221,  ..., 0.4167, 0.3381, 0.4591]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de802df5-ad4c-4765-b7b3-624d8866e374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
